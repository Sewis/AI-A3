{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M52xQdUmKC5P",
        "colab_type": "text"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UIVkzrHJ9Ip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "import pandas\n",
        "import numpy\n",
        "import math\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from statistics import mean\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtayT6YWKCME",
        "colab_type": "text"
      },
      "source": [
        "# Data Import & Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjA2_EFuNJsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace_nan(x):\n",
        "    if x == \" \":\n",
        "        return numpy.nan\n",
        "    else:\n",
        "        return float(x)\n",
        "\n",
        "def remove_nan_values(x):\n",
        "    return [e for e in x if not math.isnan(e)]  "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JDu58t9NQo6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0179de7-2eab-4632-9998-3e557b260f59"
      },
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "train_file = \"/content/drive/My Drive/data/Train.csv\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVn6sOf-NTik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "a9a1595a-68a8-4354-b204-64cd0dd54c44"
      },
      "source": [
        "data_set = pandas.read_csv(train_file)\n",
        "\n",
        "features = [\"temp\", \"precip\", \"rel_humidity\", \"wind_dir\", \"wind_spd\", \"atmos_press\"]   \n",
        "for feature in features : \n",
        "    data_set[feature] = data_set[feature].apply(lambda x: [replace_nan(X) for X in x.replace(\"nan\", \" \").split(\",\")])\n",
        "    data_set[feature] = data_set[feature].apply(remove_nan_values)\n",
        "\n",
        "for x in range(121):\n",
        "    data_set[\"temp\" + str(x)] = data_set.temp.str[x]\n",
        "    data_set[\"precip\" + str(x)] = data_set.precip.str[x]\n",
        "    data_set[\"rel_humidity\" + str(x)] = data_set.rel_humidity.str[x]\n",
        "    data_set[\"wind_dir\" + str(x)] = data_set.wind_dir.str[x]\n",
        "    data_set[\"wind_spd\" + str(x)] = data_set.wind_spd.str[x]\n",
        "    data_set[\"atmos_press\" + str(x)] = data_set.atmos_press.str[x]\n",
        "\n",
        "data_set.drop(features, 1, inplace = True)\n",
        "\n",
        "display(data_set.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>location</th>\n",
              "      <th>target</th>\n",
              "      <th>temp0</th>\n",
              "      <th>precip0</th>\n",
              "      <th>rel_humidity0</th>\n",
              "      <th>wind_dir0</th>\n",
              "      <th>wind_spd0</th>\n",
              "      <th>atmos_press0</th>\n",
              "      <th>temp1</th>\n",
              "      <th>precip1</th>\n",
              "      <th>rel_humidity1</th>\n",
              "      <th>wind_dir1</th>\n",
              "      <th>wind_spd1</th>\n",
              "      <th>atmos_press1</th>\n",
              "      <th>temp2</th>\n",
              "      <th>precip2</th>\n",
              "      <th>rel_humidity2</th>\n",
              "      <th>wind_dir2</th>\n",
              "      <th>wind_spd2</th>\n",
              "      <th>atmos_press2</th>\n",
              "      <th>temp3</th>\n",
              "      <th>precip3</th>\n",
              "      <th>rel_humidity3</th>\n",
              "      <th>wind_dir3</th>\n",
              "      <th>wind_spd3</th>\n",
              "      <th>atmos_press3</th>\n",
              "      <th>temp4</th>\n",
              "      <th>precip4</th>\n",
              "      <th>rel_humidity4</th>\n",
              "      <th>wind_dir4</th>\n",
              "      <th>wind_spd4</th>\n",
              "      <th>atmos_press4</th>\n",
              "      <th>temp5</th>\n",
              "      <th>precip5</th>\n",
              "      <th>rel_humidity5</th>\n",
              "      <th>wind_dir5</th>\n",
              "      <th>wind_spd5</th>\n",
              "      <th>atmos_press5</th>\n",
              "      <th>temp6</th>\n",
              "      <th>...</th>\n",
              "      <th>rel_humidity114</th>\n",
              "      <th>wind_dir114</th>\n",
              "      <th>wind_spd114</th>\n",
              "      <th>atmos_press114</th>\n",
              "      <th>temp115</th>\n",
              "      <th>precip115</th>\n",
              "      <th>rel_humidity115</th>\n",
              "      <th>wind_dir115</th>\n",
              "      <th>wind_spd115</th>\n",
              "      <th>atmos_press115</th>\n",
              "      <th>temp116</th>\n",
              "      <th>precip116</th>\n",
              "      <th>rel_humidity116</th>\n",
              "      <th>wind_dir116</th>\n",
              "      <th>wind_spd116</th>\n",
              "      <th>atmos_press116</th>\n",
              "      <th>temp117</th>\n",
              "      <th>precip117</th>\n",
              "      <th>rel_humidity117</th>\n",
              "      <th>wind_dir117</th>\n",
              "      <th>wind_spd117</th>\n",
              "      <th>atmos_press117</th>\n",
              "      <th>temp118</th>\n",
              "      <th>precip118</th>\n",
              "      <th>rel_humidity118</th>\n",
              "      <th>wind_dir118</th>\n",
              "      <th>wind_spd118</th>\n",
              "      <th>atmos_press118</th>\n",
              "      <th>temp119</th>\n",
              "      <th>precip119</th>\n",
              "      <th>rel_humidity119</th>\n",
              "      <th>wind_dir119</th>\n",
              "      <th>wind_spd119</th>\n",
              "      <th>atmos_press119</th>\n",
              "      <th>temp120</th>\n",
              "      <th>precip120</th>\n",
              "      <th>rel_humidity120</th>\n",
              "      <th>wind_dir120</th>\n",
              "      <th>wind_spd120</th>\n",
              "      <th>atmos_press120</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_train_0</td>\n",
              "      <td>C</td>\n",
              "      <td>45.126304</td>\n",
              "      <td>26.909091</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.510818</td>\n",
              "      <td>272.902752</td>\n",
              "      <td>0.800909</td>\n",
              "      <td>87.777273</td>\n",
              "      <td>27.208333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.535417</td>\n",
              "      <td>104.565241</td>\n",
              "      <td>1.073333</td>\n",
              "      <td>87.652500</td>\n",
              "      <td>26.183333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.614500</td>\n",
              "      <td>167.177225</td>\n",
              "      <td>1.517500</td>\n",
              "      <td>87.614167</td>\n",
              "      <td>24.700000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.633000</td>\n",
              "      <td>165.332855</td>\n",
              "      <td>1.462500</td>\n",
              "      <td>87.637500</td>\n",
              "      <td>23.658333</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.683750</td>\n",
              "      <td>111.208901</td>\n",
              "      <td>0.516667</td>\n",
              "      <td>87.717500</td>\n",
              "      <td>22.741667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.761500</td>\n",
              "      <td>86.041616</td>\n",
              "      <td>0.295000</td>\n",
              "      <td>87.762500</td>\n",
              "      <td>22.158333</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_train_1</td>\n",
              "      <td>D</td>\n",
              "      <td>79.131702</td>\n",
              "      <td>22.533333</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.744583</td>\n",
              "      <td>281.664310</td>\n",
              "      <td>2.377500</td>\n",
              "      <td>90.320000</td>\n",
              "      <td>21.716667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.808083</td>\n",
              "      <td>89.156293</td>\n",
              "      <td>1.126667</td>\n",
              "      <td>90.377500</td>\n",
              "      <td>20.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.911167</td>\n",
              "      <td>81.968539</td>\n",
              "      <td>0.700833</td>\n",
              "      <td>90.440833</td>\n",
              "      <td>20.983333</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.916333</td>\n",
              "      <td>291.018632</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>90.472500</td>\n",
              "      <td>20.875000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.929750</td>\n",
              "      <td>279.391524</td>\n",
              "      <td>0.440833</td>\n",
              "      <td>90.454167</td>\n",
              "      <td>20.141667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.954000</td>\n",
              "      <td>158.026892</td>\n",
              "      <td>0.380000</td>\n",
              "      <td>90.394167</td>\n",
              "      <td>19.375000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.600083</td>\n",
              "      <td>97.603374</td>\n",
              "      <td>1.395833</td>\n",
              "      <td>90.481667</td>\n",
              "      <td>30.233333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.556917</td>\n",
              "      <td>69.085542</td>\n",
              "      <td>1.589167</td>\n",
              "      <td>90.354167</td>\n",
              "      <td>30.583333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.520833</td>\n",
              "      <td>171.660338</td>\n",
              "      <td>1.695833</td>\n",
              "      <td>90.272500</td>\n",
              "      <td>28.466667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.603083</td>\n",
              "      <td>183.291765</td>\n",
              "      <td>2.548333</td>\n",
              "      <td>90.266667</td>\n",
              "      <td>26.991667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.651000</td>\n",
              "      <td>213.937567</td>\n",
              "      <td>1.369167</td>\n",
              "      <td>90.325833</td>\n",
              "      <td>26.025000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.649250</td>\n",
              "      <td>73.528733</td>\n",
              "      <td>1.475833</td>\n",
              "      <td>90.439167</td>\n",
              "      <td>21.450000</td>\n",
              "      <td>0.561</td>\n",
              "      <td>0.797333</td>\n",
              "      <td>296.967254</td>\n",
              "      <td>1.019167</td>\n",
              "      <td>90.529167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_train_10</td>\n",
              "      <td>A</td>\n",
              "      <td>32.661304</td>\n",
              "      <td>28.975000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.573333</td>\n",
              "      <td>328.682914</td>\n",
              "      <td>1.032500</td>\n",
              "      <td>88.551667</td>\n",
              "      <td>27.950000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.597167</td>\n",
              "      <td>307.825146</td>\n",
              "      <td>1.193333</td>\n",
              "      <td>88.464167</td>\n",
              "      <td>29.600000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.566833</td>\n",
              "      <td>319.017751</td>\n",
              "      <td>1.275833</td>\n",
              "      <td>88.319167</td>\n",
              "      <td>26.425000</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.627667</td>\n",
              "      <td>264.865746</td>\n",
              "      <td>1.493333</td>\n",
              "      <td>88.240000</td>\n",
              "      <td>22.091667</td>\n",
              "      <td>0.136</td>\n",
              "      <td>0.755417</td>\n",
              "      <td>253.217152</td>\n",
              "      <td>1.870833</td>\n",
              "      <td>88.230000</td>\n",
              "      <td>21.775000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.777417</td>\n",
              "      <td>251.433371</td>\n",
              "      <td>1.844167</td>\n",
              "      <td>88.268333</td>\n",
              "      <td>22.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.881333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.448333</td>\n",
              "      <td>23.541667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.734750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.500000</td>\n",
              "      <td>26.408333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.603000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.495000</td>\n",
              "      <td>28.075000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.496667</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.515833</td>\n",
              "      <td>29.241667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.459583</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.475833</td>\n",
              "      <td>30.091667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.437917</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.415833</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_train_100</td>\n",
              "      <td>A</td>\n",
              "      <td>53.850238</td>\n",
              "      <td>22.966667</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.843083</td>\n",
              "      <td>300.085057</td>\n",
              "      <td>1.446667</td>\n",
              "      <td>88.615000</td>\n",
              "      <td>24.266667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.790250</td>\n",
              "      <td>293.676960</td>\n",
              "      <td>1.192500</td>\n",
              "      <td>88.530833</td>\n",
              "      <td>25.275000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>294.517465</td>\n",
              "      <td>1.324167</td>\n",
              "      <td>88.400000</td>\n",
              "      <td>25.625000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.728000</td>\n",
              "      <td>301.921417</td>\n",
              "      <td>1.544167</td>\n",
              "      <td>88.271667</td>\n",
              "      <td>25.866667</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.704917</td>\n",
              "      <td>334.568073</td>\n",
              "      <td>1.915833</td>\n",
              "      <td>88.207500</td>\n",
              "      <td>25.091667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.741167</td>\n",
              "      <td>319.576411</td>\n",
              "      <td>1.840000</td>\n",
              "      <td>88.178333</td>\n",
              "      <td>24.025000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.970167</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.382500</td>\n",
              "      <td>17.625000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.983833</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.406667</td>\n",
              "      <td>18.308333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.990833</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.449167</td>\n",
              "      <td>20.325000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.930417</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.507500</td>\n",
              "      <td>21.900000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.856500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.500000</td>\n",
              "      <td>23.533333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.766417</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.490833</td>\n",
              "      <td>24.641667</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.719667</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.465833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_train_1000</td>\n",
              "      <td>A</td>\n",
              "      <td>177.418750</td>\n",
              "      <td>21.875000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.856417</td>\n",
              "      <td>21.839974</td>\n",
              "      <td>0.197500</td>\n",
              "      <td>88.556667</td>\n",
              "      <td>21.575000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.874917</td>\n",
              "      <td>17.054053</td>\n",
              "      <td>0.244167</td>\n",
              "      <td>88.640833</td>\n",
              "      <td>21.525000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.879833</td>\n",
              "      <td>89.264060</td>\n",
              "      <td>0.411667</td>\n",
              "      <td>88.658333</td>\n",
              "      <td>21.433333</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.860167</td>\n",
              "      <td>123.585424</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>88.647500</td>\n",
              "      <td>20.508333</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>328.708314</td>\n",
              "      <td>0.577500</td>\n",
              "      <td>88.632500</td>\n",
              "      <td>19.916667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.908500</td>\n",
              "      <td>117.606956</td>\n",
              "      <td>0.429167</td>\n",
              "      <td>88.586667</td>\n",
              "      <td>18.991667</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 729 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              ID location      target  ...  wind_dir120  wind_spd120  atmos_press120\n",
              "0     ID_train_0        C   45.126304  ...          NaN          NaN             NaN\n",
              "1     ID_train_1        D   79.131702  ...   296.967254     1.019167       90.529167\n",
              "2    ID_train_10        A   32.661304  ...          NaN          NaN             NaN\n",
              "3   ID_train_100        A   53.850238  ...          NaN          NaN       88.465833\n",
              "4  ID_train_1000        A  177.418750  ...          NaN          NaN             NaN\n",
              "\n",
              "[5 rows x 729 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xpbsx9rKM5L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b6c19c5-48c9-4606-9ee4-f02749b94ead"
      },
      "source": [
        "training_data = data_set.drop([\"ID\", 'location', 'target'], axis = 1)\n",
        "training_data = numpy.nan_to_num(training_data, copy = True, nan = 0)\n",
        "training_data = StandardScaler().fit(training_data).transform(training_data)\n",
        "training_data = numpy.reshape(training_data, (-1, 726, 1))\n",
        "\n",
        "training_target = data_set.target\n",
        "\n",
        "print(training_data)\n",
        "print(training_target)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 1.14015773]\n",
            "  [-0.11814189]\n",
            "  [-1.87490884]\n",
            "  ...\n",
            "  [-0.83192083]\n",
            "  [-0.76945147]\n",
            "  [-2.13617479]]\n",
            "\n",
            " [[-0.07653575]\n",
            "  [-0.04493134]\n",
            "  [-0.32621089]\n",
            "  ...\n",
            "  [ 1.53638789]\n",
            "  [ 0.6631622 ]\n",
            "  [ 0.50793318]]\n",
            "\n",
            " [[ 1.7145904 ]\n",
            "  [-0.11814189]\n",
            "  [-1.46074494]\n",
            "  ...\n",
            "  [-0.83192083]\n",
            "  [-0.76945147]\n",
            "  [-2.13617479]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.91287029]\n",
            "  [-0.11814189]\n",
            "  [-0.07998111]\n",
            "  ...\n",
            "  [-0.27021171]\n",
            "  [ 2.65335895]\n",
            "  [ 0.50907713]]\n",
            "\n",
            " [[ 1.7841037 ]\n",
            "  [-0.11814189]\n",
            "  [-1.09636904]\n",
            "  ...\n",
            "  [ 0.37770597]\n",
            "  [ 1.03800797]\n",
            "  [ 0.50201871]]\n",
            "\n",
            " [[-0.37776007]\n",
            "  [-0.10594013]\n",
            "  [ 0.79176062]\n",
            "  ...\n",
            "  [ 1.79367743]\n",
            "  [ 0.41365549]\n",
            "  [ 0.42982812]]]\n",
            "0         45.126304\n",
            "1         79.131702\n",
            "2         32.661304\n",
            "3         53.850238\n",
            "4        177.418750\n",
            "            ...    \n",
            "15534     44.850286\n",
            "15535     24.330455\n",
            "15536     38.972128\n",
            "15537     41.720952\n",
            "15538    127.983333\n",
            "Name: target, Length: 15539, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SET7d9B0PCLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folds=8\n",
        "\n",
        "def gen():\n",
        "    kfold = KFold(n_splits = folds, shuffle = True)\n",
        "    for train, test in kfold.split(training_data, training_target):\n",
        "        X_train, X_test = training_data[train], training_data[test]\n",
        "        y_train, y_test = training_target[train], training_target[test] \n",
        "        yield X_train, y_train, X_test, y_test\n",
        "\n",
        "datasets = tensorflow.data.Dataset.from_generator(gen, (tensorflow.float64, tensorflow.float64, tensorflow.float64, tensorflow.float64))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVzYF89OOT6w",
        "colab_type": "text"
      },
      "source": [
        "# Create CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHorTh6DOYao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn = tensorflow.keras.Sequential([\n",
        "    tensorflow.keras.layers.Conv1D(filters = 16, kernel_size = 4, activation = 'relu', input_shape = (726,1)),\n",
        "    tensorflow.keras.layers.Conv1D(filters = 16, kernel_size = 4, activation = 'relu'),\n",
        "    tensorflow.keras.layers.MaxPool1D(pool_size = 4),\n",
        "    tensorflow.keras.layers.Conv1D(filters = 8, kernel_size = 2, activation = 'relu'),\n",
        "    tensorflow.keras.layers.Conv1D(filters = 8, kernel_size = 2, activation = 'relu'),\n",
        "    tensorflow.keras.layers.MaxPool1D(pool_size = 2),\n",
        "    tensorflow.keras.layers.Flatten(),\n",
        "    tensorflow.keras.layers.Dense(16, activation = 'relu'),\n",
        "    tensorflow.keras.layers.Dense(1)\n",
        "])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNWlln2pOvUd",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6dT8iUuPQcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorflow.random.set_seed(12345)\n",
        "epochs = 16"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otPYfa4uOx6X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "986f8805-69c8-4890-e668-c30da7cc8c05"
      },
      "source": [
        "cnn.compile(optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.003), loss='mse', metrics=[tensorflow.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "results = []\n",
        "\n",
        "for i in range(3):\n",
        "    fold = 0\n",
        "    for train_data, validate_data, train_target, validate_target in datasets:\n",
        "        fold = fold + 1\n",
        "        print(\"\\n--- Training fold \" + str(fold) + \" of \" + str(folds) + \" ---\")\n",
        "        result = cnn.fit(train_data, validate_data, epochs = epochs, shuffle = False, validation_data = (train_target, validate_target))\n",
        "        results.append(result.history)\n",
        "    epochs = int(epochs/2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--- Training fold 1 of 8 ---\n",
            "Epoch 1/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 1863.4578 - root_mean_squared_error: 43.1678 - val_loss: 1672.4104 - val_root_mean_squared_error: 40.8951\n",
            "Epoch 2/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 1499.9772 - root_mean_squared_error: 38.7295 - val_loss: 1440.8929 - val_root_mean_squared_error: 37.9591\n",
            "Epoch 3/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 1358.0151 - root_mean_squared_error: 36.8513 - val_loss: 1335.4216 - val_root_mean_squared_error: 36.5434\n",
            "Epoch 4/16\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 1263.2922 - root_mean_squared_error: 35.5428 - val_loss: 1280.5077 - val_root_mean_squared_error: 35.7842\n",
            "Epoch 5/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 1197.0382 - root_mean_squared_error: 34.5982 - val_loss: 1241.7643 - val_root_mean_squared_error: 35.2387\n",
            "Epoch 6/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 1144.2703 - root_mean_squared_error: 33.8271 - val_loss: 1228.9529 - val_root_mean_squared_error: 35.0564\n",
            "Epoch 7/16\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 1102.7070 - root_mean_squared_error: 33.2070 - val_loss: 1206.6272 - val_root_mean_squared_error: 34.7365\n",
            "Epoch 8/16\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 1063.2563 - root_mean_squared_error: 32.6076 - val_loss: 1198.0636 - val_root_mean_squared_error: 34.6131\n",
            "Epoch 9/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 1025.1296 - root_mean_squared_error: 32.0176 - val_loss: 1171.2743 - val_root_mean_squared_error: 34.2239\n",
            "Epoch 10/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 996.0248 - root_mean_squared_error: 31.5599 - val_loss: 1172.0111 - val_root_mean_squared_error: 34.2346\n",
            "Epoch 11/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 962.3640 - root_mean_squared_error: 31.0220 - val_loss: 1158.3439 - val_root_mean_squared_error: 34.0345\n",
            "Epoch 12/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 930.9968 - root_mean_squared_error: 30.5122 - val_loss: 1158.3132 - val_root_mean_squared_error: 34.0340\n",
            "Epoch 13/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 902.4892 - root_mean_squared_error: 30.0415 - val_loss: 1168.8785 - val_root_mean_squared_error: 34.1889\n",
            "Epoch 14/16\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 872.9271 - root_mean_squared_error: 29.5453 - val_loss: 1159.5574 - val_root_mean_squared_error: 34.0523\n",
            "Epoch 15/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 843.9370 - root_mean_squared_error: 29.0506 - val_loss: 1179.1499 - val_root_mean_squared_error: 34.3388\n",
            "Epoch 16/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 817.5936 - root_mean_squared_error: 28.5936 - val_loss: 1168.1669 - val_root_mean_squared_error: 34.1785\n",
            "\n",
            "--- Training fold 2 of 8 ---\n",
            "Epoch 1/16\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 844.5792 - root_mean_squared_error: 29.0616 - val_loss: 917.2245 - val_root_mean_squared_error: 30.2857\n",
            "Epoch 2/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 812.8064 - root_mean_squared_error: 28.5098 - val_loss: 917.7729 - val_root_mean_squared_error: 30.2948\n",
            "Epoch 3/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 777.7333 - root_mean_squared_error: 27.8879 - val_loss: 934.2961 - val_root_mean_squared_error: 30.5663\n",
            "Epoch 4/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 749.8298 - root_mean_squared_error: 27.3830 - val_loss: 960.7396 - val_root_mean_squared_error: 30.9958\n",
            "Epoch 5/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 721.1511 - root_mean_squared_error: 26.8543 - val_loss: 968.7434 - val_root_mean_squared_error: 31.1246\n",
            "Epoch 6/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 702.0818 - root_mean_squared_error: 26.4968 - val_loss: 1014.0105 - val_root_mean_squared_error: 31.8435\n",
            "Epoch 7/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 674.6672 - root_mean_squared_error: 25.9744 - val_loss: 1022.8226 - val_root_mean_squared_error: 31.9816\n",
            "Epoch 8/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 659.0211 - root_mean_squared_error: 25.6714 - val_loss: 1043.6659 - val_root_mean_squared_error: 32.3058\n",
            "Epoch 9/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 644.7371 - root_mean_squared_error: 25.3917 - val_loss: 1058.5668 - val_root_mean_squared_error: 32.5356\n",
            "Epoch 10/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 631.9210 - root_mean_squared_error: 25.1380 - val_loss: 1103.9374 - val_root_mean_squared_error: 33.2256\n",
            "Epoch 11/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 626.8677 - root_mean_squared_error: 25.0373 - val_loss: 1137.9031 - val_root_mean_squared_error: 33.7328\n",
            "Epoch 12/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 609.9658 - root_mean_squared_error: 24.6975 - val_loss: 1115.8021 - val_root_mean_squared_error: 33.4036\n",
            "Epoch 13/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 612.5735 - root_mean_squared_error: 24.7502 - val_loss: 1163.9706 - val_root_mean_squared_error: 34.1170\n",
            "Epoch 14/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 601.1644 - root_mean_squared_error: 24.5187 - val_loss: 1192.3268 - val_root_mean_squared_error: 34.5301\n",
            "Epoch 15/16\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 585.5895 - root_mean_squared_error: 24.1990 - val_loss: 1182.0962 - val_root_mean_squared_error: 34.3816\n",
            "Epoch 16/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 589.2801 - root_mean_squared_error: 24.2751 - val_loss: 1173.4152 - val_root_mean_squared_error: 34.2551\n",
            "\n",
            "--- Training fold 3 of 8 ---\n",
            "Epoch 1/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 704.2826 - root_mean_squared_error: 26.5383 - val_loss: 702.6796 - val_root_mean_squared_error: 26.5081\n",
            "Epoch 2/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 655.0873 - root_mean_squared_error: 25.5947 - val_loss: 771.8002 - val_root_mean_squared_error: 27.7813\n",
            "Epoch 3/16\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 622.1601 - root_mean_squared_error: 24.9431 - val_loss: 772.2058 - val_root_mean_squared_error: 27.7886\n",
            "Epoch 4/16\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 605.9496 - root_mean_squared_error: 24.6160 - val_loss: 808.8257 - val_root_mean_squared_error: 28.4399\n",
            "Epoch 5/16\n",
            "425/425 [==============================] - 17s 40ms/step - loss: 592.4052 - root_mean_squared_error: 24.3394 - val_loss: 796.9729 - val_root_mean_squared_error: 28.2307\n",
            "Epoch 6/16\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 579.0380 - root_mean_squared_error: 24.0632 - val_loss: 822.8190 - val_root_mean_squared_error: 28.6848\n",
            "Epoch 7/16\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 573.7463 - root_mean_squared_error: 23.9530 - val_loss: 867.3997 - val_root_mean_squared_error: 29.4516\n",
            "Epoch 8/16\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 564.2372 - root_mean_squared_error: 23.7537 - val_loss: 917.8812 - val_root_mean_squared_error: 30.2966\n",
            "Epoch 9/16\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 564.7811 - root_mean_squared_error: 23.7651 - val_loss: 957.0532 - val_root_mean_squared_error: 30.9363\n",
            "Epoch 10/16\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 561.2477 - root_mean_squared_error: 23.6907 - val_loss: 940.0454 - val_root_mean_squared_error: 30.6602\n",
            "Epoch 11/16\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 549.7854 - root_mean_squared_error: 23.4475 - val_loss: 956.6070 - val_root_mean_squared_error: 30.9291\n",
            "Epoch 12/16\n",
            "425/425 [==============================] - 12s 29ms/step - loss: 538.5778 - root_mean_squared_error: 23.2073 - val_loss: 971.4755 - val_root_mean_squared_error: 31.1685\n",
            "Epoch 13/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 546.2429 - root_mean_squared_error: 23.3718 - val_loss: 1001.2550 - val_root_mean_squared_error: 31.6426\n",
            "Epoch 14/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 547.4871 - root_mean_squared_error: 23.3984 - val_loss: 979.1764 - val_root_mean_squared_error: 31.2918\n",
            "Epoch 15/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 544.5867 - root_mean_squared_error: 23.3364 - val_loss: 1051.7194 - val_root_mean_squared_error: 32.4302\n",
            "Epoch 16/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 539.8374 - root_mean_squared_error: 23.2344 - val_loss: 1045.0525 - val_root_mean_squared_error: 32.3273\n",
            "\n",
            "--- Training fold 4 of 8 ---\n",
            "Epoch 1/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 636.0509 - root_mean_squared_error: 25.2200 - val_loss: 714.5190 - val_root_mean_squared_error: 26.7305\n",
            "Epoch 2/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 575.6399 - root_mean_squared_error: 23.9925 - val_loss: 727.0096 - val_root_mean_squared_error: 26.9631\n",
            "Epoch 3/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 552.7676 - root_mean_squared_error: 23.5110 - val_loss: 732.3882 - val_root_mean_squared_error: 27.0627\n",
            "Epoch 4/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 531.0778 - root_mean_squared_error: 23.0451 - val_loss: 746.9188 - val_root_mean_squared_error: 27.3298\n",
            "Epoch 5/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 517.4985 - root_mean_squared_error: 22.7486 - val_loss: 761.7177 - val_root_mean_squared_error: 27.5992\n",
            "Epoch 6/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 511.8239 - root_mean_squared_error: 22.6235 - val_loss: 792.1904 - val_root_mean_squared_error: 28.1459\n",
            "Epoch 7/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 509.2504 - root_mean_squared_error: 22.5666 - val_loss: 761.3267 - val_root_mean_squared_error: 27.5921\n",
            "Epoch 8/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 505.5061 - root_mean_squared_error: 22.4835 - val_loss: 807.3790 - val_root_mean_squared_error: 28.4144\n",
            "Epoch 9/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 500.6729 - root_mean_squared_error: 22.3757 - val_loss: 805.7832 - val_root_mean_squared_error: 28.3863\n",
            "Epoch 10/16\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 494.9395 - root_mean_squared_error: 22.2472 - val_loss: 813.6594 - val_root_mean_squared_error: 28.5247\n",
            "Epoch 11/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 489.6410 - root_mean_squared_error: 22.1278 - val_loss: 838.7748 - val_root_mean_squared_error: 28.9616\n",
            "Epoch 12/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 490.2146 - root_mean_squared_error: 22.1408 - val_loss: 888.0102 - val_root_mean_squared_error: 29.7995\n",
            "Epoch 13/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 485.8157 - root_mean_squared_error: 22.0412 - val_loss: 881.2957 - val_root_mean_squared_error: 29.6866\n",
            "Epoch 14/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 474.8549 - root_mean_squared_error: 21.7912 - val_loss: 878.6417 - val_root_mean_squared_error: 29.6419\n",
            "Epoch 15/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 485.9904 - root_mean_squared_error: 22.0452 - val_loss: 942.3702 - val_root_mean_squared_error: 30.6980\n",
            "Epoch 16/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 479.2719 - root_mean_squared_error: 21.8923 - val_loss: 954.9891 - val_root_mean_squared_error: 30.9029\n",
            "\n",
            "--- Training fold 5 of 8 ---\n",
            "Epoch 1/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 561.5073 - root_mean_squared_error: 23.6961 - val_loss: 603.4988 - val_root_mean_squared_error: 24.5662\n",
            "Epoch 2/16\n",
            "425/425 [==============================] - 11s 25ms/step - loss: 532.1625 - root_mean_squared_error: 23.0686 - val_loss: 665.2651 - val_root_mean_squared_error: 25.7927\n",
            "Epoch 3/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 496.4659 - root_mean_squared_error: 22.2815 - val_loss: 670.0601 - val_root_mean_squared_error: 25.8855\n",
            "Epoch 4/16\n",
            "425/425 [==============================] - 11s 25ms/step - loss: 492.7393 - root_mean_squared_error: 22.1977 - val_loss: 722.0007 - val_root_mean_squared_error: 26.8701\n",
            "Epoch 5/16\n",
            "425/425 [==============================] - 11s 25ms/step - loss: 481.0598 - root_mean_squared_error: 21.9331 - val_loss: 671.3592 - val_root_mean_squared_error: 25.9106\n",
            "Epoch 6/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 480.9467 - root_mean_squared_error: 21.9305 - val_loss: 670.3506 - val_root_mean_squared_error: 25.8911\n",
            "Epoch 7/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 470.7399 - root_mean_squared_error: 21.6965 - val_loss: 711.2919 - val_root_mean_squared_error: 26.6701\n",
            "Epoch 8/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 475.7276 - root_mean_squared_error: 21.8112 - val_loss: 674.3152 - val_root_mean_squared_error: 25.9676\n",
            "Epoch 9/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 467.4441 - root_mean_squared_error: 21.6205 - val_loss: 705.9779 - val_root_mean_squared_error: 26.5702\n",
            "Epoch 10/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 457.6552 - root_mean_squared_error: 21.3929 - val_loss: 732.3267 - val_root_mean_squared_error: 27.0615\n",
            "Epoch 11/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 459.1849 - root_mean_squared_error: 21.4286 - val_loss: 810.2806 - val_root_mean_squared_error: 28.4654\n",
            "Epoch 12/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 454.4061 - root_mean_squared_error: 21.3168 - val_loss: 753.1756 - val_root_mean_squared_error: 27.4440\n",
            "Epoch 13/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 462.4611 - root_mean_squared_error: 21.5049 - val_loss: 764.5691 - val_root_mean_squared_error: 27.6508\n",
            "Epoch 14/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 457.0191 - root_mean_squared_error: 21.3780 - val_loss: 775.5833 - val_root_mean_squared_error: 27.8493\n",
            "Epoch 15/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 449.8970 - root_mean_squared_error: 21.2108 - val_loss: 749.6683 - val_root_mean_squared_error: 27.3801\n",
            "Epoch 16/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 453.6606 - root_mean_squared_error: 21.2993 - val_loss: 795.9898 - val_root_mean_squared_error: 28.2133\n",
            "\n",
            "--- Training fold 6 of 8 ---\n",
            "Epoch 1/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 513.0925 - root_mean_squared_error: 22.6515 - val_loss: 566.9141 - val_root_mean_squared_error: 23.8100\n",
            "Epoch 2/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 491.9056 - root_mean_squared_error: 22.1789 - val_loss: 588.3503 - val_root_mean_squared_error: 24.2559\n",
            "Epoch 3/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 474.6614 - root_mean_squared_error: 21.7867 - val_loss: 585.5318 - val_root_mean_squared_error: 24.1978\n",
            "Epoch 4/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 462.8543 - root_mean_squared_error: 21.5140 - val_loss: 582.7947 - val_root_mean_squared_error: 24.1411\n",
            "Epoch 5/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 459.8610 - root_mean_squared_error: 21.4444 - val_loss: 614.1753 - val_root_mean_squared_error: 24.7826\n",
            "Epoch 6/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 454.2879 - root_mean_squared_error: 21.3140 - val_loss: 633.5391 - val_root_mean_squared_error: 25.1702\n",
            "Epoch 7/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 451.9815 - root_mean_squared_error: 21.2599 - val_loss: 721.6271 - val_root_mean_squared_error: 26.8631\n",
            "Epoch 8/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 447.8512 - root_mean_squared_error: 21.1625 - val_loss: 630.2012 - val_root_mean_squared_error: 25.1038\n",
            "Epoch 9/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 452.8692 - root_mean_squared_error: 21.2807 - val_loss: 664.2349 - val_root_mean_squared_error: 25.7728\n",
            "Epoch 10/16\n",
            "425/425 [==============================] - 15s 35ms/step - loss: 444.5534 - root_mean_squared_error: 21.0844 - val_loss: 657.1052 - val_root_mean_squared_error: 25.6341\n",
            "Epoch 11/16\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 447.7568 - root_mean_squared_error: 21.1603 - val_loss: 697.5093 - val_root_mean_squared_error: 26.4104\n",
            "Epoch 12/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 438.9735 - root_mean_squared_error: 20.9517 - val_loss: 684.0021 - val_root_mean_squared_error: 26.1534\n",
            "Epoch 13/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 433.5263 - root_mean_squared_error: 20.8213 - val_loss: 695.6642 - val_root_mean_squared_error: 26.3754\n",
            "Epoch 14/16\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 428.1894 - root_mean_squared_error: 20.6927 - val_loss: 682.2516 - val_root_mean_squared_error: 26.1199\n",
            "Epoch 15/16\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 425.0717 - root_mean_squared_error: 20.6173 - val_loss: 713.3242 - val_root_mean_squared_error: 26.7081\n",
            "Epoch 16/16\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 421.2124 - root_mean_squared_error: 20.5235 - val_loss: 753.3276 - val_root_mean_squared_error: 27.4468\n",
            "\n",
            "--- Training fold 7 of 8 ---\n",
            "Epoch 1/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 506.9174 - root_mean_squared_error: 22.5148 - val_loss: 528.7123 - val_root_mean_squared_error: 22.9937\n",
            "Epoch 2/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 466.6440 - root_mean_squared_error: 21.6019 - val_loss: 537.6045 - val_root_mean_squared_error: 23.1863\n",
            "Epoch 3/16\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 447.0354 - root_mean_squared_error: 21.1432 - val_loss: 565.2880 - val_root_mean_squared_error: 23.7758\n",
            "Epoch 4/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 431.9432 - root_mean_squared_error: 20.7832 - val_loss: 581.9041 - val_root_mean_squared_error: 24.1227\n",
            "Epoch 5/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 426.8215 - root_mean_squared_error: 20.6597 - val_loss: 570.7144 - val_root_mean_squared_error: 23.8896\n",
            "Epoch 6/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 424.7703 - root_mean_squared_error: 20.6100 - val_loss: 590.1188 - val_root_mean_squared_error: 24.2924\n",
            "Epoch 7/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 426.7504 - root_mean_squared_error: 20.6579 - val_loss: 599.4509 - val_root_mean_squared_error: 24.4837\n",
            "Epoch 8/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 425.3870 - root_mean_squared_error: 20.6249 - val_loss: 639.4301 - val_root_mean_squared_error: 25.2870\n",
            "Epoch 9/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 426.0455 - root_mean_squared_error: 20.6409 - val_loss: 613.2444 - val_root_mean_squared_error: 24.7638\n",
            "Epoch 10/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 418.8275 - root_mean_squared_error: 20.4653 - val_loss: 611.9487 - val_root_mean_squared_error: 24.7376\n",
            "Epoch 11/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 417.5018 - root_mean_squared_error: 20.4329 - val_loss: 630.7836 - val_root_mean_squared_error: 25.1154\n",
            "Epoch 12/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 408.3501 - root_mean_squared_error: 20.2077 - val_loss: 670.9329 - val_root_mean_squared_error: 25.9024\n",
            "Epoch 13/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 411.1042 - root_mean_squared_error: 20.2757 - val_loss: 700.1400 - val_root_mean_squared_error: 26.4602\n",
            "Epoch 14/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 408.9153 - root_mean_squared_error: 20.2217 - val_loss: 663.9685 - val_root_mean_squared_error: 25.7676\n",
            "Epoch 15/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 408.1827 - root_mean_squared_error: 20.2035 - val_loss: 708.3994 - val_root_mean_squared_error: 26.6158\n",
            "Epoch 16/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 413.3410 - root_mean_squared_error: 20.3308 - val_loss: 718.5730 - val_root_mean_squared_error: 26.8062\n",
            "\n",
            "--- Training fold 8 of 8 ---\n",
            "Epoch 1/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 452.7819 - root_mean_squared_error: 21.2787 - val_loss: 566.0380 - val_root_mean_squared_error: 23.7916\n",
            "Epoch 2/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 427.2278 - root_mean_squared_error: 20.6695 - val_loss: 579.8054 - val_root_mean_squared_error: 24.0791\n",
            "Epoch 3/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 415.2874 - root_mean_squared_error: 20.3786 - val_loss: 614.1277 - val_root_mean_squared_error: 24.7816\n",
            "Epoch 4/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 404.7138 - root_mean_squared_error: 20.1175 - val_loss: 600.2342 - val_root_mean_squared_error: 24.4997\n",
            "Epoch 5/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 411.9862 - root_mean_squared_error: 20.2974 - val_loss: 633.2964 - val_root_mean_squared_error: 25.1654\n",
            "Epoch 6/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 419.9697 - root_mean_squared_error: 20.4932 - val_loss: 632.8683 - val_root_mean_squared_error: 25.1569\n",
            "Epoch 7/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 400.6744 - root_mean_squared_error: 20.0169 - val_loss: 667.0720 - val_root_mean_squared_error: 25.8277\n",
            "Epoch 8/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 390.1832 - root_mean_squared_error: 19.7531 - val_loss: 641.0112 - val_root_mean_squared_error: 25.3182\n",
            "Epoch 9/16\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 391.5888 - root_mean_squared_error: 19.7886 - val_loss: 646.1268 - val_root_mean_squared_error: 25.4190\n",
            "Epoch 10/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 395.4130 - root_mean_squared_error: 19.8850 - val_loss: 668.8010 - val_root_mean_squared_error: 25.8612\n",
            "Epoch 11/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 398.9000 - root_mean_squared_error: 19.9725 - val_loss: 642.7077 - val_root_mean_squared_error: 25.3517\n",
            "Epoch 12/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 397.7660 - root_mean_squared_error: 19.9441 - val_loss: 703.6744 - val_root_mean_squared_error: 26.5269\n",
            "Epoch 13/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 390.1044 - root_mean_squared_error: 19.7511 - val_loss: 697.6915 - val_root_mean_squared_error: 26.4139\n",
            "Epoch 14/16\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 388.7892 - root_mean_squared_error: 19.7177 - val_loss: 686.6633 - val_root_mean_squared_error: 26.2043\n",
            "Epoch 15/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 388.9376 - root_mean_squared_error: 19.7215 - val_loss: 719.6483 - val_root_mean_squared_error: 26.8263\n",
            "Epoch 16/16\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 393.9368 - root_mean_squared_error: 19.8478 - val_loss: 753.1860 - val_root_mean_squared_error: 27.4442\n",
            "\n",
            "--- Training fold 1 of 8 ---\n",
            "Epoch 1/8\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 456.7124 - root_mean_squared_error: 21.3708 - val_loss: 534.6155 - val_root_mean_squared_error: 23.1218\n",
            "Epoch 2/8\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 434.1597 - root_mean_squared_error: 20.8365 - val_loss: 526.0166 - val_root_mean_squared_error: 22.9351\n",
            "Epoch 3/8\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 417.5032 - root_mean_squared_error: 20.4329 - val_loss: 505.7825 - val_root_mean_squared_error: 22.4896\n",
            "Epoch 4/8\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 403.9269 - root_mean_squared_error: 20.0979 - val_loss: 512.6871 - val_root_mean_squared_error: 22.6426\n",
            "Epoch 5/8\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 397.7782 - root_mean_squared_error: 19.9444 - val_loss: 525.1182 - val_root_mean_squared_error: 22.9155\n",
            "Epoch 6/8\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 394.7524 - root_mean_squared_error: 19.8684 - val_loss: 542.7168 - val_root_mean_squared_error: 23.2963\n",
            "Epoch 7/8\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 392.9376 - root_mean_squared_error: 19.8227 - val_loss: 547.6386 - val_root_mean_squared_error: 23.4017\n",
            "Epoch 8/8\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 392.8104 - root_mean_squared_error: 19.8194 - val_loss: 560.9333 - val_root_mean_squared_error: 23.6840\n",
            "\n",
            "--- Training fold 2 of 8 ---\n",
            "Epoch 1/8\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 431.1608 - root_mean_squared_error: 20.7644 - val_loss: 457.1773 - val_root_mean_squared_error: 21.3817\n",
            "Epoch 2/8\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 408.0874 - root_mean_squared_error: 20.2012 - val_loss: 488.5264 - val_root_mean_squared_error: 22.1026\n",
            "Epoch 3/8\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 393.0002 - root_mean_squared_error: 19.8242 - val_loss: 500.1879 - val_root_mean_squared_error: 22.3649\n",
            "Epoch 4/8\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 397.0419 - root_mean_squared_error: 19.9259 - val_loss: 507.4265 - val_root_mean_squared_error: 22.5261\n",
            "Epoch 5/8\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 386.8592 - root_mean_squared_error: 19.6687 - val_loss: 530.1525 - val_root_mean_squared_error: 23.0250\n",
            "Epoch 6/8\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 388.0060 - root_mean_squared_error: 19.6979 - val_loss: 555.8954 - val_root_mean_squared_error: 23.5774\n",
            "Epoch 7/8\n",
            "425/425 [==============================] - 15s 35ms/step - loss: 389.9025 - root_mean_squared_error: 19.7459 - val_loss: 564.4664 - val_root_mean_squared_error: 23.7585\n",
            "Epoch 8/8\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 387.6514 - root_mean_squared_error: 19.6889 - val_loss: 561.0369 - val_root_mean_squared_error: 23.6862\n",
            "\n",
            "--- Training fold 3 of 8 ---\n",
            "Epoch 1/8\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 419.1214 - root_mean_squared_error: 20.4725 - val_loss: 501.9162 - val_root_mean_squared_error: 22.4035\n",
            "Epoch 2/8\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 405.7369 - root_mean_squared_error: 20.1429 - val_loss: 554.5455 - val_root_mean_squared_error: 23.5488\n",
            "Epoch 3/8\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 391.1951 - root_mean_squared_error: 19.7787 - val_loss: 532.5132 - val_root_mean_squared_error: 23.0762\n",
            "Epoch 4/8\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 376.8614 - root_mean_squared_error: 19.4129 - val_loss: 538.5923 - val_root_mean_squared_error: 23.2076\n",
            "Epoch 5/8\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 376.8540 - root_mean_squared_error: 19.4127 - val_loss: 561.5168 - val_root_mean_squared_error: 23.6963\n",
            "Epoch 6/8\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 374.8972 - root_mean_squared_error: 19.3623 - val_loss: 568.2744 - val_root_mean_squared_error: 23.8385\n",
            "Epoch 7/8\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 379.8499 - root_mean_squared_error: 19.4897 - val_loss: 575.8626 - val_root_mean_squared_error: 23.9971\n",
            "Epoch 8/8\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 387.6503 - root_mean_squared_error: 19.6888 - val_loss: 630.2479 - val_root_mean_squared_error: 25.1047\n",
            "\n",
            "--- Training fold 4 of 8 ---\n",
            "Epoch 1/8\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 409.7283 - root_mean_squared_error: 20.2417 - val_loss: 500.6945 - val_root_mean_squared_error: 22.3762\n",
            "Epoch 2/8\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 385.4319 - root_mean_squared_error: 19.6324 - val_loss: 489.3069 - val_root_mean_squared_error: 22.1203\n",
            "Epoch 3/8\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 380.8493 - root_mean_squared_error: 19.5154 - val_loss: 494.6190 - val_root_mean_squared_error: 22.2400\n",
            "Epoch 4/8\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 380.1957 - root_mean_squared_error: 19.4986 - val_loss: 551.0515 - val_root_mean_squared_error: 23.4745\n",
            "Epoch 5/8\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 373.1927 - root_mean_squared_error: 19.3182 - val_loss: 516.4987 - val_root_mean_squared_error: 22.7266\n",
            "Epoch 6/8\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 376.4164 - root_mean_squared_error: 19.4015 - val_loss: 529.5041 - val_root_mean_squared_error: 23.0110\n",
            "Epoch 7/8\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 372.2708 - root_mean_squared_error: 19.2943 - val_loss: 551.7953 - val_root_mean_squared_error: 23.4903\n",
            "Epoch 8/8\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 374.3941 - root_mean_squared_error: 19.3493 - val_loss: 544.4810 - val_root_mean_squared_error: 23.3341\n",
            "\n",
            "--- Training fold 5 of 8 ---\n",
            "Epoch 1/8\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 403.2309 - root_mean_squared_error: 20.0806 - val_loss: 506.4830 - val_root_mean_squared_error: 22.5052\n",
            "Epoch 2/8\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 394.4369 - root_mean_squared_error: 19.8604 - val_loss: 513.8344 - val_root_mean_squared_error: 22.6679\n",
            "Epoch 3/8\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 374.1117 - root_mean_squared_error: 19.3420 - val_loss: 532.6743 - val_root_mean_squared_error: 23.0797\n",
            "Epoch 4/8\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 367.5816 - root_mean_squared_error: 19.1724 - val_loss: 520.9473 - val_root_mean_squared_error: 22.8243\n",
            "Epoch 5/8\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 362.6433 - root_mean_squared_error: 19.0432 - val_loss: 508.5827 - val_root_mean_squared_error: 22.5518\n",
            "Epoch 6/8\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 362.1018 - root_mean_squared_error: 19.0290 - val_loss: 521.6204 - val_root_mean_squared_error: 22.8390\n",
            "Epoch 7/8\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 362.3964 - root_mean_squared_error: 19.0367 - val_loss: 538.9259 - val_root_mean_squared_error: 23.2148\n",
            "Epoch 8/8\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 361.0438 - root_mean_squared_error: 19.0012 - val_loss: 553.6956 - val_root_mean_squared_error: 23.5307\n",
            "\n",
            "--- Training fold 6 of 8 ---\n",
            "Epoch 1/8\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 391.0305 - root_mean_squared_error: 19.7745 - val_loss: 476.6412 - val_root_mean_squared_error: 21.8321\n",
            "Epoch 2/8\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 373.5376 - root_mean_squared_error: 19.3271 - val_loss: 532.6508 - val_root_mean_squared_error: 23.0792\n",
            "Epoch 3/8\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 371.6196 - root_mean_squared_error: 19.2774 - val_loss: 532.4822 - val_root_mean_squared_error: 23.0756\n",
            "Epoch 4/8\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 365.0377 - root_mean_squared_error: 19.1060 - val_loss: 534.2204 - val_root_mean_squared_error: 23.1132\n",
            "Epoch 5/8\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 362.4461 - root_mean_squared_error: 19.0380 - val_loss: 550.1805 - val_root_mean_squared_error: 23.4559\n",
            "Epoch 6/8\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 369.8123 - root_mean_squared_error: 19.2305 - val_loss: 580.2936 - val_root_mean_squared_error: 24.0893\n",
            "Epoch 7/8\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 379.5158 - root_mean_squared_error: 19.4812 - val_loss: 580.0754 - val_root_mean_squared_error: 24.0848\n",
            "Epoch 8/8\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 370.2899 - root_mean_squared_error: 19.2429 - val_loss: 614.1718 - val_root_mean_squared_error: 24.7825\n",
            "\n",
            "--- Training fold 7 of 8 ---\n",
            "Epoch 1/8\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 399.3226 - root_mean_squared_error: 19.9831 - val_loss: 529.0256 - val_root_mean_squared_error: 23.0006\n",
            "Epoch 2/8\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 377.5461 - root_mean_squared_error: 19.4305 - val_loss: 512.4995 - val_root_mean_squared_error: 22.6385\n",
            "Epoch 3/8\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 368.9478 - root_mean_squared_error: 19.2080 - val_loss: 548.0435 - val_root_mean_squared_error: 23.4103\n",
            "Epoch 4/8\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 364.8405 - root_mean_squared_error: 19.1008 - val_loss: 549.1661 - val_root_mean_squared_error: 23.4343\n",
            "Epoch 5/8\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 363.5678 - root_mean_squared_error: 19.0675 - val_loss: 557.3603 - val_root_mean_squared_error: 23.6085\n",
            "Epoch 6/8\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 360.3048 - root_mean_squared_error: 18.9817 - val_loss: 616.5222 - val_root_mean_squared_error: 24.8299\n",
            "Epoch 7/8\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 366.3771 - root_mean_squared_error: 19.1410 - val_loss: 611.5825 - val_root_mean_squared_error: 24.7302\n",
            "Epoch 8/8\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 369.6775 - root_mean_squared_error: 19.2270 - val_loss: 579.0413 - val_root_mean_squared_error: 24.0633\n",
            "\n",
            "--- Training fold 8 of 8 ---\n",
            "Epoch 1/8\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 397.4375 - root_mean_squared_error: 19.9358 - val_loss: 519.2311 - val_root_mean_squared_error: 22.7866\n",
            "Epoch 2/8\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 371.9189 - root_mean_squared_error: 19.2852 - val_loss: 495.3813 - val_root_mean_squared_error: 22.2572\n",
            "Epoch 3/8\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 364.4633 - root_mean_squared_error: 19.0909 - val_loss: 535.8708 - val_root_mean_squared_error: 23.1489\n",
            "Epoch 4/8\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 364.2686 - root_mean_squared_error: 19.0858 - val_loss: 533.2212 - val_root_mean_squared_error: 23.0916\n",
            "Epoch 5/8\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 361.6810 - root_mean_squared_error: 19.0179 - val_loss: 624.9022 - val_root_mean_squared_error: 24.9980\n",
            "Epoch 6/8\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 366.5656 - root_mean_squared_error: 19.1459 - val_loss: 532.8984 - val_root_mean_squared_error: 23.0846\n",
            "Epoch 7/8\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 365.5526 - root_mean_squared_error: 19.1194 - val_loss: 560.0129 - val_root_mean_squared_error: 23.6646\n",
            "Epoch 8/8\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 358.4641 - root_mean_squared_error: 18.9331 - val_loss: 528.1382 - val_root_mean_squared_error: 22.9813\n",
            "\n",
            "--- Training fold 1 of 8 ---\n",
            "Epoch 1/4\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 384.0360 - root_mean_squared_error: 19.5968 - val_loss: 519.7274 - val_root_mean_squared_error: 22.7975\n",
            "Epoch 2/4\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 360.4641 - root_mean_squared_error: 18.9859 - val_loss: 498.1974 - val_root_mean_squared_error: 22.3203\n",
            "Epoch 3/4\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 349.9112 - root_mean_squared_error: 18.7059 - val_loss: 566.4218 - val_root_mean_squared_error: 23.7996\n",
            "Epoch 4/4\n",
            "425/425 [==============================] - 15s 36ms/step - loss: 356.1383 - root_mean_squared_error: 18.8716 - val_loss: 568.1121 - val_root_mean_squared_error: 23.8351\n",
            "\n",
            "--- Training fold 2 of 8 ---\n",
            "Epoch 1/4\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 374.7877 - root_mean_squared_error: 19.3594 - val_loss: 509.4649 - val_root_mean_squared_error: 22.5713\n",
            "Epoch 2/4\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 367.4041 - root_mean_squared_error: 19.1678 - val_loss: 497.6265 - val_root_mean_squared_error: 22.3075\n",
            "Epoch 3/4\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 361.0996 - root_mean_squared_error: 19.0026 - val_loss: 525.1189 - val_root_mean_squared_error: 22.9155\n",
            "Epoch 4/4\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 347.6135 - root_mean_squared_error: 18.6444 - val_loss: 549.7812 - val_root_mean_squared_error: 23.4474\n",
            "\n",
            "--- Training fold 3 of 8 ---\n",
            "Epoch 1/4\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 370.6824 - root_mean_squared_error: 19.2531 - val_loss: 438.5672 - val_root_mean_squared_error: 20.9420\n",
            "Epoch 2/4\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 368.5563 - root_mean_squared_error: 19.1978 - val_loss: 438.1643 - val_root_mean_squared_error: 20.9324\n",
            "Epoch 3/4\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 356.1491 - root_mean_squared_error: 18.8719 - val_loss: 496.4578 - val_root_mean_squared_error: 22.2813\n",
            "Epoch 4/4\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 350.5699 - root_mean_squared_error: 18.7235 - val_loss: 513.8242 - val_root_mean_squared_error: 22.6677\n",
            "\n",
            "--- Training fold 4 of 8 ---\n",
            "Epoch 1/4\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 366.6657 - root_mean_squared_error: 19.1485 - val_loss: 442.7482 - val_root_mean_squared_error: 21.0416\n",
            "Epoch 2/4\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 361.5759 - root_mean_squared_error: 19.0151 - val_loss: 421.5495 - val_root_mean_squared_error: 20.5317\n",
            "Epoch 3/4\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 355.6265 - root_mean_squared_error: 18.8581 - val_loss: 515.3848 - val_root_mean_squared_error: 22.7021\n",
            "Epoch 4/4\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 355.7303 - root_mean_squared_error: 18.8608 - val_loss: 466.0486 - val_root_mean_squared_error: 21.5882\n",
            "\n",
            "--- Training fold 5 of 8 ---\n",
            "Epoch 1/4\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 365.5760 - root_mean_squared_error: 19.1200 - val_loss: 546.4489 - val_root_mean_squared_error: 23.3762\n",
            "Epoch 2/4\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 363.3973 - root_mean_squared_error: 19.0630 - val_loss: 592.9648 - val_root_mean_squared_error: 24.3509\n",
            "Epoch 3/4\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 349.3937 - root_mean_squared_error: 18.6921 - val_loss: 547.2576 - val_root_mean_squared_error: 23.3935\n",
            "Epoch 4/4\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 344.3349 - root_mean_squared_error: 18.5563 - val_loss: 582.6328 - val_root_mean_squared_error: 24.1378\n",
            "\n",
            "--- Training fold 6 of 8 ---\n",
            "Epoch 1/4\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 360.6683 - root_mean_squared_error: 18.9913 - val_loss: 441.7790 - val_root_mean_squared_error: 21.0185\n",
            "Epoch 2/4\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 356.0289 - root_mean_squared_error: 18.8687 - val_loss: 492.2872 - val_root_mean_squared_error: 22.1875\n",
            "Epoch 3/4\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 351.6540 - root_mean_squared_error: 18.7524 - val_loss: 527.0239 - val_root_mean_squared_error: 22.9570\n",
            "Epoch 4/4\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 351.3441 - root_mean_squared_error: 18.7442 - val_loss: 501.8434 - val_root_mean_squared_error: 22.4019\n",
            "\n",
            "--- Training fold 7 of 8 ---\n",
            "Epoch 1/4\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 359.9827 - root_mean_squared_error: 18.9732 - val_loss: 504.4858 - val_root_mean_squared_error: 22.4608\n",
            "Epoch 2/4\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 355.3803 - root_mean_squared_error: 18.8515 - val_loss: 538.5536 - val_root_mean_squared_error: 23.2068\n",
            "Epoch 3/4\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 343.2102 - root_mean_squared_error: 18.5259 - val_loss: 540.1962 - val_root_mean_squared_error: 23.2421\n",
            "Epoch 4/4\n",
            "425/425 [==============================] - 11s 26ms/step - loss: 341.2074 - root_mean_squared_error: 18.4718 - val_loss: 483.9378 - val_root_mean_squared_error: 21.9986\n",
            "\n",
            "--- Training fold 8 of 8 ---\n",
            "Epoch 1/4\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 350.8860 - root_mean_squared_error: 18.7320 - val_loss: 485.4796 - val_root_mean_squared_error: 22.0336\n",
            "Epoch 2/4\n",
            "425/425 [==============================] - 12s 28ms/step - loss: 346.0880 - root_mean_squared_error: 18.6034 - val_loss: 497.4283 - val_root_mean_squared_error: 22.3031\n",
            "Epoch 3/4\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 344.3577 - root_mean_squared_error: 18.5569 - val_loss: 542.5193 - val_root_mean_squared_error: 23.2920\n",
            "Epoch 4/4\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 335.1992 - root_mean_squared_error: 18.3084 - val_loss: 534.5159 - val_root_mean_squared_error: 23.1196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NWIf7nJPlcB",
        "colab_type": "text"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0mjrPUQkkAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TrainingLoss = [d['loss'] for d in results]\n",
        "TrainingRMSE = [d['root_mean_squared_error'] for d in results]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcCCsO9jgTZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ValidationLoss = [d['val_loss'] for d in results]\n",
        "ValidationRMSE = [d['val_root_mean_squared_error'] for d in results]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ACNqYm2koTN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "1331725c-6980-4e6d-8971-8ae990131923"
      },
      "source": [
        "print(\"Training Loss:\" + str(TrainingLoss))\n",
        "print(\"Validation Loss:\" + str(ValidationLoss))\n",
        "print(\"Training RMSE:\" + str(TrainingRMSE))\n",
        "print(\"Validation RMSE:\" + str(ValidationRMSE))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss:[[1863.457763671875, 1499.9771728515625, 1358.01513671875, 1263.292236328125, 1197.0382080078125, 1144.270263671875, 1102.70703125, 1063.25634765625, 1025.129638671875, 996.0248413085938, 962.364013671875, 930.9967651367188, 902.4891967773438, 872.9271240234375, 843.93701171875, 817.5935668945312], [844.5792236328125, 812.806396484375, 777.7332763671875, 749.8297729492188, 721.1510620117188, 702.081787109375, 674.667236328125, 659.0210571289062, 644.737060546875, 631.9209594726562, 626.8677368164062, 609.9658203125, 612.573486328125, 601.1643676757812, 585.5895385742188, 589.2800903320312], [704.2825927734375, 655.0872802734375, 622.1600952148438, 605.9496459960938, 592.4052124023438, 579.0379638671875, 573.746337890625, 564.2371826171875, 564.7811279296875, 561.2477416992188, 549.785400390625, 538.5777587890625, 546.242919921875, 547.487060546875, 544.586669921875, 539.83740234375], [636.0509033203125, 575.639892578125, 552.7676391601562, 531.0778198242188, 517.4984741210938, 511.8238830566406, 509.2503967285156, 505.5061340332031, 500.6728820800781, 494.93951416015625, 489.6410217285156, 490.2145690917969, 485.81573486328125, 474.8548889160156, 485.99041748046875, 479.2718505859375], [561.5072631835938, 532.1624755859375, 496.4659118652344, 492.7393493652344, 481.059814453125, 480.9466552734375, 470.73992919921875, 475.72760009765625, 467.444091796875, 457.6551818847656, 459.1849365234375, 454.4061279296875, 462.4610595703125, 457.0190734863281, 449.89697265625, 453.6605529785156], [513.0924682617188, 491.90557861328125, 474.6614074707031, 462.8543395996094, 459.8609924316406, 454.2878723144531, 451.98150634765625, 447.8511657714844, 452.8692321777344, 444.5534362792969, 447.75677490234375, 438.9735107421875, 433.52630615234375, 428.18939208984375, 425.07171630859375, 421.2124328613281], [506.91741943359375, 466.64404296875, 447.035400390625, 431.9432373046875, 426.82147216796875, 424.7702941894531, 426.75042724609375, 425.38702392578125, 426.0455322265625, 418.82745361328125, 417.5018310546875, 408.3500671386719, 411.10418701171875, 408.9152526855469, 408.1827392578125, 413.34100341796875], [452.7818908691406, 427.2278137207031, 415.2873840332031, 404.71380615234375, 411.9862060546875, 419.9696960449219, 400.6744384765625, 390.1832275390625, 391.5887756347656, 395.4129943847656, 398.89996337890625, 397.7660217285156, 390.1044006347656, 388.78924560546875, 388.93756103515625, 393.9367980957031], [456.7123718261719, 434.15972900390625, 417.5032043457031, 403.9268798828125, 397.7781677246094, 394.75244140625, 392.93756103515625, 392.81036376953125], [431.1607971191406, 408.08740234375, 393.000244140625, 397.04193115234375, 386.8592224121094, 388.0059509277344, 389.9024963378906, 387.65142822265625], [419.1213684082031, 405.73687744140625, 391.19512939453125, 376.86138916015625, 376.8539733886719, 374.897216796875, 379.84991455078125, 387.6502990722656], [409.728271484375, 385.43194580078125, 380.8492736816406, 380.19573974609375, 373.1927185058594, 376.4164123535156, 372.2707824707031, 374.3941345214844], [403.23089599609375, 394.4368591308594, 374.1117248535156, 367.5815734863281, 362.6433410644531, 362.1018371582031, 362.3963623046875, 361.0438232421875], [391.0305480957031, 373.5375671386719, 371.61962890625, 365.0377197265625, 362.44610595703125, 369.81231689453125, 379.51580810546875, 370.2898864746094], [399.3226318359375, 377.54608154296875, 368.9478454589844, 364.8405456542969, 363.5677795410156, 360.3048095703125, 366.3771057128906, 369.677490234375], [397.4375, 371.9189453125, 364.4632568359375, 364.2685852050781, 361.6809997558594, 366.5655517578125, 365.5526123046875, 358.4640808105469], [384.0360412597656, 360.4640808105469, 349.9111633300781, 356.1383361816406], [374.7876892089844, 367.40411376953125, 361.0996398925781, 347.613525390625], [370.682373046875, 368.55633544921875, 356.1490783691406, 350.56988525390625], [366.66571044921875, 361.57586669921875, 355.62646484375, 355.7303466796875], [365.5760498046875, 363.3973388671875, 349.39373779296875, 344.3349304199219], [360.6683349609375, 356.02886962890625, 351.6539611816406, 351.3441162109375], [359.982666015625, 355.3803405761719, 343.210205078125, 341.2073669433594], [350.88604736328125, 346.08795166015625, 344.3576965332031, 335.1992492675781]]\n",
            "Validation Loss:[[1672.410400390625, 1440.8929443359375, 1335.421630859375, 1280.5076904296875, 1241.7642822265625, 1228.952880859375, 1206.627197265625, 1198.0635986328125, 1171.2742919921875, 1172.0111083984375, 1158.3438720703125, 1158.313232421875, 1168.8785400390625, 1159.557373046875, 1179.14990234375, 1168.1668701171875], [917.2244873046875, 917.77294921875, 934.2960815429688, 960.7395629882812, 968.743408203125, 1014.010498046875, 1022.8226318359375, 1043.6658935546875, 1058.5667724609375, 1103.9373779296875, 1137.903076171875, 1115.8021240234375, 1163.9705810546875, 1192.3267822265625, 1182.09619140625, 1173.4151611328125], [702.6796264648438, 771.8002319335938, 772.205810546875, 808.8257446289062, 796.972900390625, 822.8189697265625, 867.399658203125, 917.8811645507812, 957.0531616210938, 940.04541015625, 956.6069946289062, 971.4755249023438, 1001.2550048828125, 979.1763916015625, 1051.7193603515625, 1045.052490234375], [714.5189819335938, 727.0095825195312, 732.38818359375, 746.9187622070312, 761.7177124023438, 792.1903686523438, 761.32666015625, 807.3790283203125, 805.783203125, 813.6593627929688, 838.7747802734375, 888.0101928710938, 881.295654296875, 878.6416625976562, 942.3702392578125, 954.9891357421875], [603.4988403320312, 665.26513671875, 670.06005859375, 722.0006713867188, 671.3591918945312, 670.3505859375, 711.2919311523438, 674.3152465820312, 705.9779052734375, 732.3267211914062, 810.2806396484375, 753.1755981445312, 764.569091796875, 775.583251953125, 749.6683349609375, 795.9898071289062], [566.9140625, 588.350341796875, 585.5317993164062, 582.7947387695312, 614.17529296875, 633.5390625, 721.6270751953125, 630.201171875, 664.23486328125, 657.105224609375, 697.5093383789062, 684.0021362304688, 695.6641845703125, 682.2516479492188, 713.3241577148438, 753.3275756835938], [528.7122802734375, 537.6044921875, 565.2879638671875, 581.904052734375, 570.7144165039062, 590.1188354492188, 599.4508666992188, 639.4301147460938, 613.244384765625, 611.9486694335938, 630.7835693359375, 670.9329223632812, 700.1399536132812, 663.968505859375, 708.3993530273438, 718.572998046875], [566.0380249023438, 579.8053588867188, 614.127685546875, 600.2341918945312, 633.2964477539062, 632.8683471679688, 667.0719604492188, 641.0111694335938, 646.1268310546875, 668.8009643554688, 642.7077026367188, 703.6744384765625, 697.6915283203125, 686.6632690429688, 719.6482543945312, 753.1859741210938], [534.615478515625, 526.0166015625, 505.782470703125, 512.6871337890625, 525.1182250976562, 542.716796875, 547.6386108398438, 560.9332885742188], [457.17730712890625, 488.52642822265625, 500.1878967285156, 507.426513671875, 530.1525268554688, 555.8953857421875, 564.4663696289062, 561.036865234375], [501.9161682128906, 554.5454711914062, 532.5132446289062, 538.59228515625, 561.5167846679688, 568.2743530273438, 575.8626098632812, 630.2479248046875], [500.6945495605469, 489.3069152832031, 494.6190185546875, 551.051513671875, 516.4986572265625, 529.5040893554688, 551.7952880859375, 544.4810180664062], [506.4830017089844, 513.8344116210938, 532.6742553710938, 520.9473266601562, 508.58270263671875, 521.6204223632812, 538.9259033203125, 553.695556640625], [476.6412353515625, 532.6508178710938, 532.4822387695312, 534.2203979492188, 550.1804809570312, 580.2936401367188, 580.075439453125, 614.1718139648438], [529.0255737304688, 512.49951171875, 548.04345703125, 549.1660766601562, 557.3602905273438, 616.5221557617188, 611.5824584960938, 579.0413208007812], [519.2310791015625, 495.3813171386719, 535.8707885742188, 533.22119140625, 624.9022216796875, 532.8983764648438, 560.0128784179688, 528.1382446289062], [519.7274169921875, 498.1973876953125, 566.4217529296875, 568.112060546875], [509.46490478515625, 497.62646484375, 525.118896484375, 549.7811889648438], [438.56719970703125, 438.1642761230469, 496.45782470703125, 513.82421875], [442.74822998046875, 421.5495300292969, 515.384765625, 466.048583984375], [546.4489135742188, 592.9647827148438, 547.2576293945312, 582.6327514648438], [441.7789611816406, 492.2872009277344, 527.02392578125, 501.8433532714844], [504.4858093261719, 538.5535888671875, 540.1961669921875, 483.9377746582031], [485.4795837402344, 497.4282531738281, 542.5193481445312, 534.5159301757812]]\n",
            "Training RMSE:[[43.16778564453125, 38.72953796386719, 36.85125732421875, 35.542823791503906, 34.59823989868164, 33.827064514160156, 33.20703125, 32.60761260986328, 32.01764678955078, 31.55986213684082, 31.021991729736328, 30.512239456176758, 30.041458129882812, 29.545339584350586, 29.050594329833984, 28.59359359741211], [29.0616455078125, 28.5097599029541, 27.887868881225586, 27.383020401000977, 26.85425567626953, 26.496826171875, 25.97435760498047, 25.671405792236328, 25.391672134399414, 25.138038635253906, 25.03732681274414, 24.697486877441406, 24.750221252441406, 24.518653869628906, 24.198957443237305, 24.27509117126465], [26.53832244873047, 25.59467315673828, 24.943138122558594, 24.616044998168945, 24.33937644958496, 24.063207626342773, 23.9530029296875, 23.753677368164062, 23.76512336730957, 23.6906681060791, 23.44750213623047, 23.207277297973633, 23.37183952331543, 23.398441314697266, 23.336380004882812, 23.23440170288086], [25.220048904418945, 23.992496490478516, 23.511011123657227, 23.04512596130371, 22.748592376708984, 22.623525619506836, 22.566577911376953, 22.483463287353516, 22.375720977783203, 22.247236251831055, 22.12783432006836, 22.140789031982422, 22.041227340698242, 21.791166305541992, 22.045190811157227, 21.89227867126465], [23.696144104003906, 23.068647384643555, 22.28151512145996, 22.19773292541504, 21.933074951171875, 21.930496215820312, 21.696542739868164, 21.811180114746094, 21.620454788208008, 21.39287757873535, 21.428600311279297, 21.316802978515625, 21.504907608032227, 21.37800407409668, 21.21077537536621, 21.29930877685547], [22.65154457092285, 22.178943634033203, 21.786725997924805, 21.514049530029297, 21.44437026977539, 21.314029693603516, 21.259857177734375, 21.162494659423828, 21.280723571777344, 21.084436416625977, 21.16026496887207, 20.95169448852539, 20.8212947845459, 20.692737579345703, 20.617267608642578, 20.523460388183594], [22.51482582092285, 21.601945877075195, 21.143211364746094, 20.783245086669922, 20.659658432006836, 20.609956741333008, 20.65793800354004, 20.62491226196289, 20.640871047973633, 20.465274810791016, 20.432861328125, 20.207674026489258, 20.27570343017578, 20.22165298461914, 20.203533172607422, 20.33078956604004], [21.278671264648438, 20.669490814208984, 20.37860107421875, 20.11750030517578, 20.297443389892578, 20.493162155151367, 20.01685333251953, 19.753055572509766, 19.788602828979492, 19.884994506835938, 19.97248077392578, 19.944072723388672, 19.751060485839844, 19.71773910522461, 19.721500396728516, 19.847841262817383], [21.370830535888672, 20.83650016784668, 20.43289566040039, 20.097932815551758, 19.94437599182129, 19.868377685546875, 19.82265281677246, 19.81944465637207], [20.76441192626953, 20.201173782348633, 19.824234008789062, 19.92591094970703, 19.668737411499023, 19.697866439819336, 19.745948791503906, 19.688865661621094], [20.472454071044922, 20.142911911010742, 19.778654098510742, 19.412918090820312, 19.41272735595703, 19.362262725830078, 19.48973846435547, 19.6888370513916], [20.241744995117188, 19.632421493530273, 19.51535987854004, 19.49860954284668, 19.31819725036621, 19.401453018188477, 19.29431915283203, 19.349267959594727], [20.080610275268555, 19.86043357849121, 19.341968536376953, 19.17241668701172, 19.043197631835938, 19.028974533081055, 19.036710739135742, 19.00115394592285], [19.774492263793945, 19.327119827270508, 19.27743911743164, 19.105960845947266, 19.03801727294922, 19.230504989624023, 19.481164932250977, 19.242918014526367], [19.98305892944336, 19.430545806884766, 19.20801544189453, 19.100799560546875, 19.067453384399414, 18.98169708251953, 19.140979766845703, 19.226999282836914], [19.935834884643555, 19.285200119018555, 19.09092140197754, 19.0858211517334, 19.017911911010742, 19.145902633666992, 19.119430541992188, 18.933147430419922], [19.596837997436523, 18.985891342163086, 18.70591163635254, 18.871627807617188], [19.359434127807617, 19.167787551879883, 19.002622604370117, 18.64439582824707], [19.25311279296875, 19.19782066345215, 18.871912002563477, 18.7235107421875], [19.148517608642578, 19.015148162841797, 18.858060836791992, 18.860815048217773], [19.12004280090332, 19.0629825592041, 18.69207763671875, 18.556262969970703], [18.991270065307617, 18.86872673034668, 18.752439498901367, 18.74417495727539], [18.973209381103516, 18.851533889770508, 18.52593421936035, 18.471799850463867], [18.731952667236328, 18.603439331054688, 18.55687713623047, 18.308446884155273]]\n",
            "Validation RMSE:[[40.89511489868164, 37.9590950012207, 36.54342269897461, 35.784183502197266, 35.23867416381836, 35.05642318725586, 34.73653793334961, 34.61305618286133, 34.22388458251953, 34.234649658203125, 34.03445053100586, 34.034000396728516, 34.188865661621094, 34.05227279663086, 34.33875274658203, 34.1784553527832], [30.285715103149414, 30.294767379760742, 30.56625747680664, 30.995800018310547, 31.124643325805664, 31.843530654907227, 31.981597900390625, 32.305816650390625, 32.535621643066406, 33.22555160522461, 33.732818603515625, 33.40362548828125, 34.11701202392578, 34.530086517333984, 34.38162612915039, 34.255149841308594], [26.50810432434082, 27.781291961669922, 27.788591384887695, 28.439861297607422, 28.230709075927734, 28.68482208251953, 29.451648712158203, 30.296554565429688, 30.936275482177734, 30.660160064697266, 30.92906379699707, 31.168502807617188, 31.642614364624023, 31.291793823242188, 32.43022155761719, 32.3272705078125], [26.730487823486328, 26.963115692138672, 27.062671661376953, 27.329814910888672, 27.599233627319336, 28.145875930786133, 27.592147827148438, 28.41441535949707, 28.386320114135742, 28.524715423583984, 28.96160888671875, 29.79949951171875, 29.68662452697754, 29.641889572143555, 30.698049545288086, 30.90289878845215], [24.566213607788086, 25.792734146118164, 25.88551902770996, 26.87006950378418, 25.910600662231445, 25.891128540039062, 26.67005729675293, 25.967580795288086, 26.57024383544922, 27.061534881591797, 28.465429306030273, 27.44404411315918, 27.650842666625977, 27.849294662475586, 27.38007164001465, 28.21329116821289], [23.80995750427246, 24.25593376159668, 24.197763442993164, 24.141141891479492, 24.782560348510742, 25.170202255249023, 26.863117218017578, 25.10380744934082, 25.772754669189453, 25.634063720703125, 26.410402297973633, 26.15343475341797, 26.375446319580078, 26.11994743347168, 26.7081298828125, 27.446813583374023], [22.993743896484375, 23.18630027770996, 23.775785446166992, 24.12268829345703, 23.889629364013672, 24.292362213134766, 24.483686447143555, 25.286954879760742, 24.763771057128906, 24.73759651184082, 25.11540412902832, 25.902372360229492, 26.46015739440918, 25.76758575439453, 26.615772247314453, 26.806211471557617], [23.791553497314453, 24.079147338867188, 24.781599044799805, 24.499677658081055, 25.165380477905273, 25.156875610351562, 25.827735900878906, 25.318199157714844, 25.419025421142578, 25.861186981201172, 25.351680755615234, 26.52686309814453, 26.413850784301758, 26.204259872436523, 26.82625961303711, 27.44423484802246], [23.121753692626953, 22.93505096435547, 22.489608764648438, 22.642595291137695, 22.91545867919922, 23.296283721923828, 23.40167999267578, 23.684030532836914], [21.381704330444336, 22.10263442993164, 22.36488151550293, 22.5261287689209, 23.025041580200195, 23.577434539794922, 23.758501052856445, 23.686216354370117], [22.403486251831055, 23.548789978027344, 23.076248168945312, 23.207592010498047, 23.696346282958984, 23.838504791259766, 23.99713706970215, 25.104738235473633], [22.376205444335938, 22.120283126831055, 22.240032196044922, 23.4744873046875, 22.726606369018555, 23.010955810546875, 23.490324020385742, 23.334117889404297], [22.505176544189453, 22.66791534423828, 23.079736709594727, 22.824270248413086, 22.55177879333496, 22.83901023864746, 23.21477699279785, 23.530736923217773], [21.832115173339844, 23.0792293548584, 23.075576782226562, 23.113208770751953, 23.4559268951416, 24.089284896850586, 24.084754943847656, 24.782489776611328], [23.00055503845215, 22.638452529907227, 23.410327911376953, 23.43429183959961, 23.608478546142578, 24.829864501953125, 24.730194091796875, 24.063278198242188], [22.78664207458496, 22.257164001464844, 23.148883819580078, 23.091583251953125, 24.998044967651367, 23.084590911865234, 23.66459083557129, 22.981258392333984], [22.797531127929688, 22.320335388183594, 23.79961585998535, 23.835102081298828], [22.57132911682129, 22.30754280090332, 22.91547203063965, 23.447412490844727], [20.94199562072754, 20.932373046875, 22.281333923339844, 22.66769027709961], [21.041584014892578, 20.53167152404785, 22.70208740234375, 21.588157653808594], [23.37624740600586, 24.350868225097656, 23.393537521362305, 24.137786865234375], [21.018539428710938, 22.187545776367188, 22.957000732421875, 22.4018611907959], [22.46076202392578, 23.206756591796875, 23.24212074279785, 21.998586654663086], [22.033601760864258, 22.303098678588867, 23.29204559326172, 23.119600296020508]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4bq0G0SrKks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "e1c3e0cd-8171-48ac-eb13-ecfc4ab17dcd"
      },
      "source": [
        "def flattenMeans(lst):\n",
        "    retList = []\n",
        "    for item in lst:\n",
        "        retList.append(mean(item))\n",
        "    return retList\n",
        "\n",
        "TrainingLoss_means = flattenMeans(TrainingLoss)\n",
        "TrainingRMSE_means = flattenMeans(TrainingRMSE)\n",
        "ValidationLoss_means = flattenMeans(ValidationLoss)\n",
        "ValidationRMSE_means = flattenMeans(ValidationRMSE)\n",
        "\n",
        "print(\"Training Loss Means:\" + str(TrainingLoss_means))\n",
        "print(\"Validation Loss Means:\" + str(ValidationLoss_means))\n",
        "print(\"Training RMSE Means:\" + str(TrainingRMSE_means))\n",
        "print(\"Validation RMSE Means:\" + str(ValidationRMSE_means))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss Means:[1115.217269897461, 677.7480545043945, 580.5907745361328, 515.0635013580322, 478.3173122406006, 453.0405082702637, 429.2835865020752, 404.266263961792, 411.3225898742676, 397.71368408203125, 389.0207710266113, 381.55990982055664, 373.443302154541, 372.9111976623535, 371.32303619384766, 368.79394149780273, 362.6374053955078, 362.7262420654297, 361.48941802978516, 359.89959716796875, 355.6755142211914, 354.92382049560547, 349.9451446533203, 344.1327362060547]\n",
            "Validation Loss Means:[1246.2709884643555, 1056.7058486938477, 897.6855278015137, 815.4358444213867, 717.232063293457, 654.4095420837402, 620.7008361816406, 653.3095092773438, 531.9385757446289, 520.6086616516113, 557.9336051940918, 522.2438812255859, 524.5954475402832, 550.0895080566406, 562.9051055908203, 541.2070121765137, 538.1146545410156, 520.4978637695312, 471.75337982177734, 461.43277740478516, 567.3260192871094, 490.73336029052734, 516.7933349609375, 514.9857788085938]\n",
            "Training RMSE Means:[33.17962992191315, 25.99041175842285, 24.078317284584045, 22.67826783657074, 21.86044156551361, 21.277743458747864, 20.710878372192383, 20.10206687450409, 20.274126291275024, 19.939643621444702, 19.720062971115112, 19.531421661376953, 19.320683240890503, 19.309702157974243, 19.267443656921387, 19.20177125930786, 19.040067195892334, 19.043560028076172, 19.01158905029297, 18.970635414123535, 18.85784149169922, 18.839152812957764, 18.70561933517456, 18.55017900466919]\n",
            "Validation RMSE Means:[35.2569899559021, 32.47372627258301, 29.910467863082886, 28.52746057510376, 26.761790990829468, 25.5590922832489, 24.8875013589859, 25.541720628738403, 23.060807704925537, 22.802817821502686, 23.609105348587036, 22.84662652015686, 22.9016752243042, 23.43907332420349, 23.714430332183838, 23.25159478187561, 23.188146114349365, 22.810439109802246, 21.705848217010498, 21.465875148773193, 23.81461000442505, 22.141236782073975, 22.7270565032959, 22.687086582183838]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EF4HOQ7jquY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "9e3cd367-3e99-4a24-d827-19b9fd8a3bbc"
      },
      "source": [
        "plt.plot(TrainingLoss_means, 'b')\n",
        "plt.plot(ValidationLoss_means, 'r')\n",
        "plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kddS14lNkGdR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "6ed2c6df-5e02-4bc7-8155-1cf117f9cd34"
      },
      "source": [
        "plt.plot(TrainingRMSE_means, 'b')\n",
        "plt.plot(ValidationRMSE_means, 'r')\n",
        "plt.legend(['Training RMSE', 'Validation RMSE'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXUhyUy7t9mP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "5d42f66c-6683-495b-9eb2-71638bbbcbd1"
      },
      "source": [
        "print(\"For the last run (last 8 folds):\")\n",
        "\n",
        "print(\"Minimum Training Loss:\\t\" + str(min(TrainingLoss_means[-8:])))\n",
        "print(\"Minimum Validation Loss:\\t\" + str(min(ValidationLoss_means[-8:])))\n",
        "print(\"Mean Training Loss:\\t\" + str(mean(TrainingLoss_means[-8:])))\n",
        "print(\"Mean Validation Loss:\\t\" + str(mean(ValidationLoss_means[-8:])))\n",
        "\n",
        "print(\"Minimum Training RMSE:\\t\" + str(min(TrainingRMSE_means[-8:])))\n",
        "print(\"Minimum Validation RMSE:\\t\" + str(min(ValidationRMSE_means[-8:])))\n",
        "print(\"Mean Training RMSE:\\t\" + str(mean(TrainingRMSE_means[-8:])))\n",
        "print(\"Mean Validation RMSE:\\t\" + str(mean(ValidationRMSE_means[-8:])))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For the last run (last 8 folds):\n",
            "Minimum Training Loss:\t344.1327362060547\n",
            "Minimum Validation Loss:\t461.43277740478516\n",
            "Mean Training Loss:\t356.4287347793579\n",
            "Mean Validation Loss:\t510.20464611053467\n",
            "Minimum Training RMSE:\t18.55017900466919\n",
            "Minimum Validation RMSE:\t21.465875148773193\n",
            "Mean Training RMSE:\t18.877330541610718\n",
            "Mean Validation RMSE:\t22.567537307739258\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}