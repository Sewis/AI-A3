{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M52xQdUmKC5P",
        "colab_type": "text"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UIVkzrHJ9Ip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "import pandas\n",
        "import numpy\n",
        "import math\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from statistics import mean\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtayT6YWKCME",
        "colab_type": "text"
      },
      "source": [
        "# Data Import & Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjA2_EFuNJsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace_nan(x):\n",
        "    if x == \" \":\n",
        "        return numpy.nan\n",
        "    else:\n",
        "        return float(x)\n",
        "\n",
        "def remove_nan_values(x):\n",
        "    return [e for e in x if not math.isnan(e)]  "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JDu58t9NQo6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "440aa1d7-04c3-49b2-f6f5-dd207bfde773"
      },
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "train_file = \"/content/drive/My Drive/data/Train.csv\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVn6sOf-NTik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "7e701bb9-2738-4b77-8347-3981070407a5"
      },
      "source": [
        "data_set = pandas.read_csv(train_file)\n",
        "\n",
        "features = [\"temp\", \"precip\", \"rel_humidity\", \"wind_dir\", \"wind_spd\", \"atmos_press\"]   \n",
        "for feature in features : \n",
        "    data_set[feature] = data_set[feature].apply(lambda x: [replace_nan(X) for X in x.replace(\"nan\", \" \").split(\",\")])\n",
        "    data_set[feature] = data_set[feature].apply(remove_nan_values)\n",
        "\n",
        "for x in range(121):\n",
        "    data_set[\"temp\" + str(x)] = data_set.temp.str[x]\n",
        "    data_set[\"precip\" + str(x)] = data_set.precip.str[x]\n",
        "    data_set[\"rel_humidity\" + str(x)] = data_set.rel_humidity.str[x]\n",
        "    data_set[\"wind_dir\" + str(x)] = data_set.wind_dir.str[x]\n",
        "    data_set[\"wind_spd\" + str(x)] = data_set.wind_spd.str[x]\n",
        "    data_set[\"atmos_press\" + str(x)] = data_set.atmos_press.str[x]\n",
        "\n",
        "data_set.drop(features, 1, inplace = True)\n",
        "\n",
        "display(data_set.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>location</th>\n",
              "      <th>target</th>\n",
              "      <th>temp0</th>\n",
              "      <th>precip0</th>\n",
              "      <th>rel_humidity0</th>\n",
              "      <th>wind_dir0</th>\n",
              "      <th>wind_spd0</th>\n",
              "      <th>atmos_press0</th>\n",
              "      <th>temp1</th>\n",
              "      <th>precip1</th>\n",
              "      <th>rel_humidity1</th>\n",
              "      <th>wind_dir1</th>\n",
              "      <th>wind_spd1</th>\n",
              "      <th>atmos_press1</th>\n",
              "      <th>temp2</th>\n",
              "      <th>precip2</th>\n",
              "      <th>rel_humidity2</th>\n",
              "      <th>wind_dir2</th>\n",
              "      <th>wind_spd2</th>\n",
              "      <th>atmos_press2</th>\n",
              "      <th>temp3</th>\n",
              "      <th>precip3</th>\n",
              "      <th>rel_humidity3</th>\n",
              "      <th>wind_dir3</th>\n",
              "      <th>wind_spd3</th>\n",
              "      <th>atmos_press3</th>\n",
              "      <th>temp4</th>\n",
              "      <th>precip4</th>\n",
              "      <th>rel_humidity4</th>\n",
              "      <th>wind_dir4</th>\n",
              "      <th>wind_spd4</th>\n",
              "      <th>atmos_press4</th>\n",
              "      <th>temp5</th>\n",
              "      <th>precip5</th>\n",
              "      <th>rel_humidity5</th>\n",
              "      <th>wind_dir5</th>\n",
              "      <th>wind_spd5</th>\n",
              "      <th>atmos_press5</th>\n",
              "      <th>temp6</th>\n",
              "      <th>...</th>\n",
              "      <th>rel_humidity114</th>\n",
              "      <th>wind_dir114</th>\n",
              "      <th>wind_spd114</th>\n",
              "      <th>atmos_press114</th>\n",
              "      <th>temp115</th>\n",
              "      <th>precip115</th>\n",
              "      <th>rel_humidity115</th>\n",
              "      <th>wind_dir115</th>\n",
              "      <th>wind_spd115</th>\n",
              "      <th>atmos_press115</th>\n",
              "      <th>temp116</th>\n",
              "      <th>precip116</th>\n",
              "      <th>rel_humidity116</th>\n",
              "      <th>wind_dir116</th>\n",
              "      <th>wind_spd116</th>\n",
              "      <th>atmos_press116</th>\n",
              "      <th>temp117</th>\n",
              "      <th>precip117</th>\n",
              "      <th>rel_humidity117</th>\n",
              "      <th>wind_dir117</th>\n",
              "      <th>wind_spd117</th>\n",
              "      <th>atmos_press117</th>\n",
              "      <th>temp118</th>\n",
              "      <th>precip118</th>\n",
              "      <th>rel_humidity118</th>\n",
              "      <th>wind_dir118</th>\n",
              "      <th>wind_spd118</th>\n",
              "      <th>atmos_press118</th>\n",
              "      <th>temp119</th>\n",
              "      <th>precip119</th>\n",
              "      <th>rel_humidity119</th>\n",
              "      <th>wind_dir119</th>\n",
              "      <th>wind_spd119</th>\n",
              "      <th>atmos_press119</th>\n",
              "      <th>temp120</th>\n",
              "      <th>precip120</th>\n",
              "      <th>rel_humidity120</th>\n",
              "      <th>wind_dir120</th>\n",
              "      <th>wind_spd120</th>\n",
              "      <th>atmos_press120</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID_train_0</td>\n",
              "      <td>C</td>\n",
              "      <td>45.126304</td>\n",
              "      <td>26.909091</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.510818</td>\n",
              "      <td>272.902752</td>\n",
              "      <td>0.800909</td>\n",
              "      <td>87.777273</td>\n",
              "      <td>27.208333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.535417</td>\n",
              "      <td>104.565241</td>\n",
              "      <td>1.073333</td>\n",
              "      <td>87.652500</td>\n",
              "      <td>26.183333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.614500</td>\n",
              "      <td>167.177225</td>\n",
              "      <td>1.517500</td>\n",
              "      <td>87.614167</td>\n",
              "      <td>24.700000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.633000</td>\n",
              "      <td>165.332855</td>\n",
              "      <td>1.462500</td>\n",
              "      <td>87.637500</td>\n",
              "      <td>23.658333</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.683750</td>\n",
              "      <td>111.208901</td>\n",
              "      <td>0.516667</td>\n",
              "      <td>87.717500</td>\n",
              "      <td>22.741667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.761500</td>\n",
              "      <td>86.041616</td>\n",
              "      <td>0.295000</td>\n",
              "      <td>87.762500</td>\n",
              "      <td>22.158333</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ID_train_1</td>\n",
              "      <td>D</td>\n",
              "      <td>79.131702</td>\n",
              "      <td>22.533333</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.744583</td>\n",
              "      <td>281.664310</td>\n",
              "      <td>2.377500</td>\n",
              "      <td>90.320000</td>\n",
              "      <td>21.716667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.808083</td>\n",
              "      <td>89.156293</td>\n",
              "      <td>1.126667</td>\n",
              "      <td>90.377500</td>\n",
              "      <td>20.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.911167</td>\n",
              "      <td>81.968539</td>\n",
              "      <td>0.700833</td>\n",
              "      <td>90.440833</td>\n",
              "      <td>20.983333</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.916333</td>\n",
              "      <td>291.018632</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>90.472500</td>\n",
              "      <td>20.875000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.929750</td>\n",
              "      <td>279.391524</td>\n",
              "      <td>0.440833</td>\n",
              "      <td>90.454167</td>\n",
              "      <td>20.141667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.954000</td>\n",
              "      <td>158.026892</td>\n",
              "      <td>0.380000</td>\n",
              "      <td>90.394167</td>\n",
              "      <td>19.375000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.600083</td>\n",
              "      <td>97.603374</td>\n",
              "      <td>1.395833</td>\n",
              "      <td>90.481667</td>\n",
              "      <td>30.233333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.556917</td>\n",
              "      <td>69.085542</td>\n",
              "      <td>1.589167</td>\n",
              "      <td>90.354167</td>\n",
              "      <td>30.583333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.520833</td>\n",
              "      <td>171.660338</td>\n",
              "      <td>1.695833</td>\n",
              "      <td>90.272500</td>\n",
              "      <td>28.466667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.603083</td>\n",
              "      <td>183.291765</td>\n",
              "      <td>2.548333</td>\n",
              "      <td>90.266667</td>\n",
              "      <td>26.991667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.651000</td>\n",
              "      <td>213.937567</td>\n",
              "      <td>1.369167</td>\n",
              "      <td>90.325833</td>\n",
              "      <td>26.025000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.649250</td>\n",
              "      <td>73.528733</td>\n",
              "      <td>1.475833</td>\n",
              "      <td>90.439167</td>\n",
              "      <td>21.450000</td>\n",
              "      <td>0.561</td>\n",
              "      <td>0.797333</td>\n",
              "      <td>296.967254</td>\n",
              "      <td>1.019167</td>\n",
              "      <td>90.529167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ID_train_10</td>\n",
              "      <td>A</td>\n",
              "      <td>32.661304</td>\n",
              "      <td>28.975000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.573333</td>\n",
              "      <td>328.682914</td>\n",
              "      <td>1.032500</td>\n",
              "      <td>88.551667</td>\n",
              "      <td>27.950000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.597167</td>\n",
              "      <td>307.825146</td>\n",
              "      <td>1.193333</td>\n",
              "      <td>88.464167</td>\n",
              "      <td>29.600000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.566833</td>\n",
              "      <td>319.017751</td>\n",
              "      <td>1.275833</td>\n",
              "      <td>88.319167</td>\n",
              "      <td>26.425000</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.627667</td>\n",
              "      <td>264.865746</td>\n",
              "      <td>1.493333</td>\n",
              "      <td>88.240000</td>\n",
              "      <td>22.091667</td>\n",
              "      <td>0.136</td>\n",
              "      <td>0.755417</td>\n",
              "      <td>253.217152</td>\n",
              "      <td>1.870833</td>\n",
              "      <td>88.230000</td>\n",
              "      <td>21.775000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.777417</td>\n",
              "      <td>251.433371</td>\n",
              "      <td>1.844167</td>\n",
              "      <td>88.268333</td>\n",
              "      <td>22.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.881333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.448333</td>\n",
              "      <td>23.541667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.734750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.500000</td>\n",
              "      <td>26.408333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.603000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.495000</td>\n",
              "      <td>28.075000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.496667</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.515833</td>\n",
              "      <td>29.241667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.459583</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.475833</td>\n",
              "      <td>30.091667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.437917</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.415833</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ID_train_100</td>\n",
              "      <td>A</td>\n",
              "      <td>53.850238</td>\n",
              "      <td>22.966667</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.843083</td>\n",
              "      <td>300.085057</td>\n",
              "      <td>1.446667</td>\n",
              "      <td>88.615000</td>\n",
              "      <td>24.266667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.790250</td>\n",
              "      <td>293.676960</td>\n",
              "      <td>1.192500</td>\n",
              "      <td>88.530833</td>\n",
              "      <td>25.275000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.737500</td>\n",
              "      <td>294.517465</td>\n",
              "      <td>1.324167</td>\n",
              "      <td>88.400000</td>\n",
              "      <td>25.625000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.728000</td>\n",
              "      <td>301.921417</td>\n",
              "      <td>1.544167</td>\n",
              "      <td>88.271667</td>\n",
              "      <td>25.866667</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.704917</td>\n",
              "      <td>334.568073</td>\n",
              "      <td>1.915833</td>\n",
              "      <td>88.207500</td>\n",
              "      <td>25.091667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.741167</td>\n",
              "      <td>319.576411</td>\n",
              "      <td>1.840000</td>\n",
              "      <td>88.178333</td>\n",
              "      <td>24.025000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.970167</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.382500</td>\n",
              "      <td>17.625000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.983833</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.406667</td>\n",
              "      <td>18.308333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.990833</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.449167</td>\n",
              "      <td>20.325000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.930417</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.507500</td>\n",
              "      <td>21.900000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.856500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.500000</td>\n",
              "      <td>23.533333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.766417</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.490833</td>\n",
              "      <td>24.641667</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.719667</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>88.465833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ID_train_1000</td>\n",
              "      <td>A</td>\n",
              "      <td>177.418750</td>\n",
              "      <td>21.875000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.856417</td>\n",
              "      <td>21.839974</td>\n",
              "      <td>0.197500</td>\n",
              "      <td>88.556667</td>\n",
              "      <td>21.575000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.874917</td>\n",
              "      <td>17.054053</td>\n",
              "      <td>0.244167</td>\n",
              "      <td>88.640833</td>\n",
              "      <td>21.525000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.879833</td>\n",
              "      <td>89.264060</td>\n",
              "      <td>0.411667</td>\n",
              "      <td>88.658333</td>\n",
              "      <td>21.433333</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.860167</td>\n",
              "      <td>123.585424</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>88.647500</td>\n",
              "      <td>20.508333</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>328.708314</td>\n",
              "      <td>0.577500</td>\n",
              "      <td>88.632500</td>\n",
              "      <td>19.916667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.908500</td>\n",
              "      <td>117.606956</td>\n",
              "      <td>0.429167</td>\n",
              "      <td>88.586667</td>\n",
              "      <td>18.991667</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 729 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              ID location      target  ...  wind_dir120  wind_spd120  atmos_press120\n",
              "0     ID_train_0        C   45.126304  ...          NaN          NaN             NaN\n",
              "1     ID_train_1        D   79.131702  ...   296.967254     1.019167       90.529167\n",
              "2    ID_train_10        A   32.661304  ...          NaN          NaN             NaN\n",
              "3   ID_train_100        A   53.850238  ...          NaN          NaN       88.465833\n",
              "4  ID_train_1000        A  177.418750  ...          NaN          NaN             NaN\n",
              "\n",
              "[5 rows x 729 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xpbsx9rKM5L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "95a82969-220b-4f58-ea01-9f30e38a57ed"
      },
      "source": [
        "training_data = data_set.drop([\"ID\", 'location', 'target'], axis = 1)\n",
        "training_data = numpy.nan_to_num(training_data, copy = True, nan = 0)\n",
        "training_data = StandardScaler().fit(training_data).transform(training_data)\n",
        "training_data = numpy.reshape(training_data, (-1, 11, 66))\n",
        "\n",
        "training_target = data_set.target\n",
        "\n",
        "print(training_data)\n",
        "print(training_target)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[ 1.14015773e+00 -1.18141889e-01 -1.87490884e+00 ...  1.25929277e+00\n",
            "   -5.63552403e-01 -1.13482531e+00]\n",
            "  [-6.72066058e-01 -1.19036327e-01  2.87137369e-01 ... -1.69296950e+00\n",
            "   -1.25992663e+00 -8.37729501e+00]\n",
            "  [-5.01088161e+00 -1.19483560e-01 -4.37428745e+00 ... -1.66484664e+00\n",
            "   -1.25702911e+00 -6.63328618e+00]\n",
            "  ...\n",
            "  [-2.67441936e+00 -1.13386069e-01 -2.56135881e+00 ... -1.31424625e+00\n",
            "   -1.19193257e+00 -2.85012993e+00]\n",
            "  [-2.44615948e+00 -1.12406024e-01 -2.43990889e+00 ... -1.11377767e+00\n",
            "   -1.00288050e+00 -2.50889371e+00]\n",
            "  [-2.21880400e+00 -1.14322240e-01 -2.22373218e+00 ... -8.31920832e-01\n",
            "   -7.69451467e-01 -2.13617479e+00]]\n",
            "\n",
            " [[-7.65357506e-02 -4.49313439e-02 -3.26210887e-01 ...  1.07152976e+00\n",
            "   -4.69867995e-01  1.21855501e+00]\n",
            "  [-1.18527806e+00 -1.06343510e-01  1.14297464e+00 ... -1.00453805e+00\n",
            "   -9.32482218e-02  2.17817687e-01]\n",
            "  [ 2.45693211e+00 -1.19483560e-01 -2.11062517e+00 ...  8.67393939e-01\n",
            "   -4.77595556e-01  2.44328022e-01]\n",
            "  ...\n",
            "  [ 7.64459105e-01 -1.13386069e-01  1.31585215e-01 ...  1.03844480e+00\n",
            "   -6.57248201e-01  4.02961941e-01]\n",
            "  [ 2.92149126e-01 -1.12406024e-01  4.32315376e-01 ...  3.29354840e-01\n",
            "   -4.56302107e-03  4.48908920e-01]\n",
            "  [ 5.57749979e-01 -1.14322240e-01  4.88065606e-01 ...  1.53638789e+00\n",
            "    6.63162201e-01  5.07933176e-01]]\n",
            "\n",
            " [[ 1.71459040e+00 -1.18141889e-01 -1.46074494e+00 ... -8.25989909e-02\n",
            "   -5.96095408e-01 -3.13896474e-01]\n",
            "  [-8.29076121e-01  3.37905066e-01  7.36900020e-01 ... -9.12582377e-01\n",
            "   -5.86685764e-01  9.19661319e-02]\n",
            "  [ 2.55833812e-01 -1.19483560e-01 -1.62387404e-01 ...  4.20986202e-01\n",
            "   -4.15340804e-02  1.08488334e-01]\n",
            "  ...\n",
            "  [ 1.64313385e-01 -1.13386069e-01  3.53434359e-01 ... -1.31424625e+00\n",
            "   -1.19193257e+00  3.13010700e-01]\n",
            "  [ 1.41190733e+00 -1.12406024e-01 -1.10399739e+00 ... -1.11377767e+00\n",
            "   -1.00288050e+00  3.72340214e-01]\n",
            "  [ 2.72292065e-01 -1.14322240e-01  5.97584147e-01 ... -8.31920832e-01\n",
            "   -7.69451467e-01 -2.13617479e+00]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 9.12870286e-01 -1.18141889e-01 -7.99811100e-02 ...  8.22150595e-01\n",
            "   -6.76959846e-01  1.46491017e+00]\n",
            "  [-4.98651956e-01 -1.19036327e-01  4.87094113e-01 ... -5.77704080e-01\n",
            "   -1.88257935e-01  2.88892413e-01]\n",
            "  [ 1.24438426e+00 -1.19483560e-01 -6.02296963e-01 ...  4.56736512e-01\n",
            "   -6.89195842e-02  2.72575060e-01]\n",
            "  ...\n",
            "  [-2.37958202e-01 -1.13386069e-01  3.00584698e-01 ... -7.41297025e-01\n",
            "    2.82218914e-01  3.91557141e-01]\n",
            "  [ 1.57749826e+00 -1.12406024e-01 -1.07752930e+00 ...  1.17852733e+00\n",
            "   -4.60612599e-01  4.38498620e-01]\n",
            "  [ 1.19096317e-01 -1.14322240e-01  7.33268450e-01 ... -2.70211707e-01\n",
            "    2.65335895e+00  5.09077127e-01]]\n",
            "\n",
            " [[ 1.78410370e+00 -1.18141889e-01 -1.09636904e+00 ... -1.42336184e+00\n",
            "   -5.10300213e-01  1.37233571e+00]\n",
            "  [-1.11966191e+00 -1.19036327e-01  7.69385987e-01 ... -8.76761978e-01\n",
            "    5.74884599e-01  2.63690302e-01]\n",
            "  [ 1.26845010e+00 -1.19483560e-01 -5.41458409e-01 ... -3.09561937e-02\n",
            "   -3.16442402e-01  2.62418821e-01]\n",
            "  ...\n",
            "  [-5.81025690e-01 -1.00121259e-01  6.82910056e-01 ...  1.57419679e+00\n",
            "    1.12309997e+00  3.91736744e-01]\n",
            "  [ 9.84803883e-01 -1.12406024e-01 -2.81741392e-01 ...  1.11911018e+00\n",
            "   -8.62435425e-02  4.43445551e-01]\n",
            "  [-1.90495767e-01 -1.14322240e-01  6.33657094e-01 ...  3.77705968e-01\n",
            "    1.03800797e+00  5.02018708e-01]]\n",
            "\n",
            " [[-3.77760070e-01 -1.05940131e-01  7.91760623e-01 ... -4.20945169e-01\n",
            "   -4.10698895e-01 -1.24652671e+00]\n",
            "  [ 4.03570052e-01 -1.19036327e-01 -1.15576630e-01 ... -3.40438750e-01\n",
            "   -7.55251383e-01 -3.35609275e-04]\n",
            "  [-6.12387464e-01 -9.04439247e-02  1.11522228e+00 ... -1.94113639e-01\n",
            "    4.53511556e-01  4.32979788e-02]\n",
            "  ...\n",
            "  [ 1.45830638e-01 -1.13386069e-01  6.15592566e-01 ...  1.34291243e+00\n",
            "   -8.77687530e-02  3.09957447e-01]\n",
            "  [ 9.29270338e-01 -1.12406024e-01 -6.51131245e-01 ... -1.89797625e-01\n",
            "   -4.52671436e-01  3.51166262e-01]\n",
            "  [ 4.20730180e-01 -1.14322240e-01  3.20011290e-01 ...  1.79367743e+00\n",
            "    4.13655487e-01  4.29828123e-01]]]\n",
            "0         45.126304\n",
            "1         79.131702\n",
            "2         32.661304\n",
            "3         53.850238\n",
            "4        177.418750\n",
            "            ...    \n",
            "15534     44.850286\n",
            "15535     24.330455\n",
            "15536     38.972128\n",
            "15537     41.720952\n",
            "15538    127.983333\n",
            "Name: target, Length: 15539, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SET7d9B0PCLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folds=8\n",
        "\n",
        "def gen():\n",
        "    kfold = KFold(n_splits = folds, shuffle = True)\n",
        "    for train, test in kfold.split(training_data, training_target):\n",
        "        X_train, X_test = training_data[train], training_data[test]\n",
        "        y_train, y_test = training_target[train], training_target[test] \n",
        "        yield X_train, y_train, X_test, y_test\n",
        "\n",
        "datasets = tensorflow.data.Dataset.from_generator(gen, (tensorflow.float64, tensorflow.float64, tensorflow.float64, tensorflow.float64))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVzYF89OOT6w",
        "colab_type": "text"
      },
      "source": [
        "# Create CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHorTh6DOYao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm = tensorflow.keras.Sequential([\n",
        "    tensorflow.keras.layers.LSTM(16, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, input_shape=(11, 66)),\n",
        "    tensorflow.keras.layers.LSTM(16, recurrent_dropout=0.2),\n",
        "    tensorflow.keras.layers.Dense(16, activation='relu'),\n",
        "    tensorflow.keras.layers.Dense(1)\n",
        "])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNWlln2pOvUd",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6dT8iUuPQcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorflow.random.set_seed(12345)\n",
        "epochs = 16"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otPYfa4uOx6X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1f945e1c-91e3-4ace-8809-1acdfc92007a"
      },
      "source": [
        "lstm.compile(optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.003), loss='mse', metrics=[tensorflow.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "results = []\n",
        "\n",
        "for i in range(3):\n",
        "    fold = 0\n",
        "    for train_data, validate_data, train_target, validate_target in datasets:\n",
        "        fold = fold + 1\n",
        "        print(\"\\n--- Training fold \" + str(fold) + \" of \" + str(folds) + \" ---\")\n",
        "        result = lstm.fit(train_data, validate_data, epochs = epochs, shuffle = False, validation_data = (train_target, validate_target))\n",
        "        results.append(result.history)\n",
        "    epochs = int(epochs/2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "--- Training fold 1 of 8 ---\n",
            "Epoch 1/16\n",
            "425/425 [==============================] - 9s 20ms/step - loss: 2377.2168 - root_mean_squared_error: 48.7567 - val_loss: 1767.4677 - val_root_mean_squared_error: 42.0413\n",
            "Epoch 2/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 1536.7845 - root_mean_squared_error: 39.2018 - val_loss: 1360.3091 - val_root_mean_squared_error: 36.8824\n",
            "Epoch 3/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 1337.8807 - root_mean_squared_error: 36.5771 - val_loss: 1204.3098 - val_root_mean_squared_error: 34.7032\n",
            "Epoch 4/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 1213.4548 - root_mean_squared_error: 34.8347 - val_loss: 1100.2737 - val_root_mean_squared_error: 33.1704\n",
            "Epoch 5/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 1104.9326 - root_mean_squared_error: 33.2405 - val_loss: 1027.0460 - val_root_mean_squared_error: 32.0476\n",
            "Epoch 6/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 1061.8232 - root_mean_squared_error: 32.5856 - val_loss: 979.7889 - val_root_mean_squared_error: 31.3016\n",
            "Epoch 7/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 1032.1233 - root_mean_squared_error: 32.1267 - val_loss: 981.4492 - val_root_mean_squared_error: 31.3281\n",
            "Epoch 8/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 1007.9620 - root_mean_squared_error: 31.7484 - val_loss: 958.8475 - val_root_mean_squared_error: 30.9653\n",
            "Epoch 9/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 1003.9928 - root_mean_squared_error: 31.6858 - val_loss: 944.4002 - val_root_mean_squared_error: 30.7311\n",
            "Epoch 10/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 981.7777 - root_mean_squared_error: 31.3333 - val_loss: 933.7855 - val_root_mean_squared_error: 30.5579\n",
            "Epoch 11/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 967.8533 - root_mean_squared_error: 31.1103 - val_loss: 944.5192 - val_root_mean_squared_error: 30.7330\n",
            "Epoch 12/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 970.4301 - root_mean_squared_error: 31.1517 - val_loss: 931.4455 - val_root_mean_squared_error: 30.5196\n",
            "Epoch 13/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 951.3105 - root_mean_squared_error: 30.8433 - val_loss: 894.5057 - val_root_mean_squared_error: 29.9083\n",
            "Epoch 14/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 926.2780 - root_mean_squared_error: 30.4348 - val_loss: 908.8477 - val_root_mean_squared_error: 30.1471\n",
            "Epoch 15/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 920.0761 - root_mean_squared_error: 30.3328 - val_loss: 899.9751 - val_root_mean_squared_error: 29.9996\n",
            "Epoch 16/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 899.1425 - root_mean_squared_error: 29.9857 - val_loss: 898.1394 - val_root_mean_squared_error: 29.9690\n",
            "\n",
            "--- Training fold 2 of 8 ---\n",
            "Epoch 1/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 903.9022 - root_mean_squared_error: 30.0650 - val_loss: 866.4250 - val_root_mean_squared_error: 29.4351\n",
            "Epoch 2/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 881.1031 - root_mean_squared_error: 29.6834 - val_loss: 863.1743 - val_root_mean_squared_error: 29.3798\n",
            "Epoch 3/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 880.2464 - root_mean_squared_error: 29.6689 - val_loss: 881.4622 - val_root_mean_squared_error: 29.6894\n",
            "Epoch 4/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 861.8655 - root_mean_squared_error: 29.3575 - val_loss: 880.7939 - val_root_mean_squared_error: 29.6782\n",
            "Epoch 5/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 843.8835 - root_mean_squared_error: 29.0497 - val_loss: 907.9523 - val_root_mean_squared_error: 30.1322\n",
            "Epoch 6/16\n",
            "425/425 [==============================] - 9s 20ms/step - loss: 844.9253 - root_mean_squared_error: 29.0676 - val_loss: 922.3812 - val_root_mean_squared_error: 30.3707\n",
            "Epoch 7/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 834.1023 - root_mean_squared_error: 28.8808 - val_loss: 952.0237 - val_root_mean_squared_error: 30.8549\n",
            "Epoch 8/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 832.4764 - root_mean_squared_error: 28.8527 - val_loss: 929.0912 - val_root_mean_squared_error: 30.4810\n",
            "Epoch 9/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 823.0703 - root_mean_squared_error: 28.6892 - val_loss: 924.8030 - val_root_mean_squared_error: 30.4106\n",
            "Epoch 10/16\n",
            "425/425 [==============================] - 8s 20ms/step - loss: 812.8389 - root_mean_squared_error: 28.5103 - val_loss: 921.9091 - val_root_mean_squared_error: 30.3630\n",
            "Epoch 11/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 811.3445 - root_mean_squared_error: 28.4841 - val_loss: 906.7443 - val_root_mean_squared_error: 30.1122\n",
            "Epoch 12/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 816.8641 - root_mean_squared_error: 28.5808 - val_loss: 952.3907 - val_root_mean_squared_error: 30.8608\n",
            "Epoch 13/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 803.4058 - root_mean_squared_error: 28.3444 - val_loss: 936.9084 - val_root_mean_squared_error: 30.6090\n",
            "Epoch 14/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 787.6437 - root_mean_squared_error: 28.0650 - val_loss: 948.2281 - val_root_mean_squared_error: 30.7933\n",
            "Epoch 15/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 790.4705 - root_mean_squared_error: 28.1153 - val_loss: 944.8389 - val_root_mean_squared_error: 30.7382\n",
            "Epoch 16/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 792.5463 - root_mean_squared_error: 28.1522 - val_loss: 961.8174 - val_root_mean_squared_error: 31.0132\n",
            "\n",
            "--- Training fold 3 of 8 ---\n",
            "Epoch 1/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 834.5140 - root_mean_squared_error: 28.8880 - val_loss: 648.0597 - val_root_mean_squared_error: 25.4570\n",
            "Epoch 2/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 838.0532 - root_mean_squared_error: 28.9491 - val_loss: 677.9410 - val_root_mean_squared_error: 26.0373\n",
            "Epoch 3/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 818.5826 - root_mean_squared_error: 28.6109 - val_loss: 680.5433 - val_root_mean_squared_error: 26.0872\n",
            "Epoch 4/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 802.8524 - root_mean_squared_error: 28.3347 - val_loss: 690.6993 - val_root_mean_squared_error: 26.2812\n",
            "Epoch 5/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 809.0422 - root_mean_squared_error: 28.4437 - val_loss: 709.2539 - val_root_mean_squared_error: 26.6318\n",
            "Epoch 6/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 793.4545 - root_mean_squared_error: 28.1683 - val_loss: 703.8679 - val_root_mean_squared_error: 26.5305\n",
            "Epoch 7/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 791.2212 - root_mean_squared_error: 28.1287 - val_loss: 703.9866 - val_root_mean_squared_error: 26.5327\n",
            "Epoch 8/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 800.9178 - root_mean_squared_error: 28.3005 - val_loss: 730.1265 - val_root_mean_squared_error: 27.0209\n",
            "Epoch 9/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 779.7031 - root_mean_squared_error: 27.9232 - val_loss: 721.2822 - val_root_mean_squared_error: 26.8567\n",
            "Epoch 10/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 798.4454 - root_mean_squared_error: 28.2568 - val_loss: 731.8481 - val_root_mean_squared_error: 27.0527\n",
            "Epoch 11/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 774.6367 - root_mean_squared_error: 27.8323 - val_loss: 732.3421 - val_root_mean_squared_error: 27.0618\n",
            "Epoch 12/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 774.4484 - root_mean_squared_error: 27.8289 - val_loss: 758.7634 - val_root_mean_squared_error: 27.5457\n",
            "Epoch 13/16\n",
            "425/425 [==============================] - 11s 27ms/step - loss: 766.0024 - root_mean_squared_error: 27.6767 - val_loss: 737.9454 - val_root_mean_squared_error: 27.1652\n",
            "Epoch 14/16\n",
            "425/425 [==============================] - 9s 20ms/step - loss: 768.2117 - root_mean_squared_error: 27.7166 - val_loss: 731.5734 - val_root_mean_squared_error: 27.0476\n",
            "Epoch 15/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 769.7732 - root_mean_squared_error: 27.7448 - val_loss: 741.8222 - val_root_mean_squared_error: 27.2364\n",
            "Epoch 16/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 788.6385 - root_mean_squared_error: 28.0827 - val_loss: 767.0629 - val_root_mean_squared_error: 27.6959\n",
            "\n",
            "--- Training fold 4 of 8 ---\n",
            "Epoch 1/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 774.3411 - root_mean_squared_error: 27.8270 - val_loss: 651.2572 - val_root_mean_squared_error: 25.5197\n",
            "Epoch 2/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 756.2119 - root_mean_squared_error: 27.4993 - val_loss: 653.7747 - val_root_mean_squared_error: 25.5690\n",
            "Epoch 3/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 760.5688 - root_mean_squared_error: 27.5784 - val_loss: 680.4395 - val_root_mean_squared_error: 26.0852\n",
            "Epoch 4/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 741.7708 - root_mean_squared_error: 27.2355 - val_loss: 697.0355 - val_root_mean_squared_error: 26.4014\n",
            "Epoch 5/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 756.9510 - root_mean_squared_error: 27.5127 - val_loss: 707.1043 - val_root_mean_squared_error: 26.5914\n",
            "Epoch 6/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 748.0164 - root_mean_squared_error: 27.3499 - val_loss: 711.2343 - val_root_mean_squared_error: 26.6690\n",
            "Epoch 7/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 747.0141 - root_mean_squared_error: 27.3316 - val_loss: 726.6372 - val_root_mean_squared_error: 26.9562\n",
            "Epoch 8/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 752.8360 - root_mean_squared_error: 27.4379 - val_loss: 745.1141 - val_root_mean_squared_error: 27.2968\n",
            "Epoch 9/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 728.4073 - root_mean_squared_error: 26.9890 - val_loss: 746.2294 - val_root_mean_squared_error: 27.3172\n",
            "Epoch 10/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 742.4679 - root_mean_squared_error: 27.2483 - val_loss: 782.5178 - val_root_mean_squared_error: 27.9735\n",
            "Epoch 11/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 728.5613 - root_mean_squared_error: 26.9919 - val_loss: 775.0990 - val_root_mean_squared_error: 27.8406\n",
            "Epoch 12/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 731.0926 - root_mean_squared_error: 27.0387 - val_loss: 758.9642 - val_root_mean_squared_error: 27.5493\n",
            "Epoch 13/16\n",
            "425/425 [==============================] - 8s 20ms/step - loss: 707.4111 - root_mean_squared_error: 26.5972 - val_loss: 775.7366 - val_root_mean_squared_error: 27.8520\n",
            "Epoch 14/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 744.8320 - root_mean_squared_error: 27.2916 - val_loss: 785.2407 - val_root_mean_squared_error: 28.0221\n",
            "Epoch 15/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 730.9606 - root_mean_squared_error: 27.0363 - val_loss: 781.6187 - val_root_mean_squared_error: 27.9574\n",
            "Epoch 16/16\n",
            "425/425 [==============================] - 8s 20ms/step - loss: 724.5790 - root_mean_squared_error: 26.9180 - val_loss: 799.1591 - val_root_mean_squared_error: 28.2694\n",
            "\n",
            "--- Training fold 5 of 8 ---\n",
            "Epoch 1/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 752.8564 - root_mean_squared_error: 27.4382 - val_loss: 566.5901 - val_root_mean_squared_error: 23.8032\n",
            "Epoch 2/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 742.3359 - root_mean_squared_error: 27.2458 - val_loss: 592.8374 - val_root_mean_squared_error: 24.3483\n",
            "Epoch 3/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 721.9939 - root_mean_squared_error: 26.8699 - val_loss: 594.0121 - val_root_mean_squared_error: 24.3724\n",
            "Epoch 4/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 723.0076 - root_mean_squared_error: 26.8888 - val_loss: 611.2372 - val_root_mean_squared_error: 24.7232\n",
            "Epoch 5/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 724.4438 - root_mean_squared_error: 26.9155 - val_loss: 609.2461 - val_root_mean_squared_error: 24.6829\n",
            "Epoch 6/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 735.6923 - root_mean_squared_error: 27.1236 - val_loss: 633.0953 - val_root_mean_squared_error: 25.1614\n",
            "Epoch 7/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 728.3965 - root_mean_squared_error: 26.9888 - val_loss: 631.0178 - val_root_mean_squared_error: 25.1201\n",
            "Epoch 8/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 737.6999 - root_mean_squared_error: 27.1606 - val_loss: 634.7578 - val_root_mean_squared_error: 25.1944\n",
            "Epoch 9/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 732.2679 - root_mean_squared_error: 27.0604 - val_loss: 650.7064 - val_root_mean_squared_error: 25.5089\n",
            "Epoch 10/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 701.3118 - root_mean_squared_error: 26.4823 - val_loss: 662.8160 - val_root_mean_squared_error: 25.7452\n",
            "Epoch 11/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 720.9191 - root_mean_squared_error: 26.8499 - val_loss: 681.8330 - val_root_mean_squared_error: 26.1119\n",
            "Epoch 12/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 718.1955 - root_mean_squared_error: 26.7992 - val_loss: 668.5792 - val_root_mean_squared_error: 25.8569\n",
            "Epoch 13/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 709.4910 - root_mean_squared_error: 26.6363 - val_loss: 685.6685 - val_root_mean_squared_error: 26.1853\n",
            "Epoch 14/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 696.9307 - root_mean_squared_error: 26.3994 - val_loss: 673.6849 - val_root_mean_squared_error: 25.9554\n",
            "Epoch 15/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 698.4012 - root_mean_squared_error: 26.4273 - val_loss: 694.2159 - val_root_mean_squared_error: 26.3480\n",
            "Epoch 16/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 709.1575 - root_mean_squared_error: 26.6300 - val_loss: 689.5149 - val_root_mean_squared_error: 26.2586\n",
            "\n",
            "--- Training fold 6 of 8 ---\n",
            "Epoch 1/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 721.5868 - root_mean_squared_error: 26.8624 - val_loss: 566.3300 - val_root_mean_squared_error: 23.7977\n",
            "Epoch 2/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 726.5634 - root_mean_squared_error: 26.9548 - val_loss: 577.5032 - val_root_mean_squared_error: 24.0313\n",
            "Epoch 3/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 720.2333 - root_mean_squared_error: 26.8372 - val_loss: 576.2108 - val_root_mean_squared_error: 24.0044\n",
            "Epoch 4/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 721.7826 - root_mean_squared_error: 26.8660 - val_loss: 582.6582 - val_root_mean_squared_error: 24.1383\n",
            "Epoch 5/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 717.9135 - root_mean_squared_error: 26.7939 - val_loss: 615.7227 - val_root_mean_squared_error: 24.8138\n",
            "Epoch 6/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 717.1007 - root_mean_squared_error: 26.7787 - val_loss: 605.2256 - val_root_mean_squared_error: 24.6013\n",
            "Epoch 7/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 708.5376 - root_mean_squared_error: 26.6184 - val_loss: 621.4053 - val_root_mean_squared_error: 24.9280\n",
            "Epoch 8/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 701.1110 - root_mean_squared_error: 26.4785 - val_loss: 621.3880 - val_root_mean_squared_error: 24.9277\n",
            "Epoch 9/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 705.7885 - root_mean_squared_error: 26.5667 - val_loss: 641.3483 - val_root_mean_squared_error: 25.3249\n",
            "Epoch 10/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 700.5889 - root_mean_squared_error: 26.4686 - val_loss: 638.5884 - val_root_mean_squared_error: 25.2703\n",
            "Epoch 11/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 709.4086 - root_mean_squared_error: 26.6347 - val_loss: 647.6380 - val_root_mean_squared_error: 25.4487\n",
            "Epoch 12/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 707.2401 - root_mean_squared_error: 26.5940 - val_loss: 656.4861 - val_root_mean_squared_error: 25.6220\n",
            "Epoch 13/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 685.3628 - root_mean_squared_error: 26.1794 - val_loss: 644.0869 - val_root_mean_squared_error: 25.3789\n",
            "Epoch 14/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 673.5078 - root_mean_squared_error: 25.9520 - val_loss: 638.3333 - val_root_mean_squared_error: 25.2653\n",
            "Epoch 15/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 718.7685 - root_mean_squared_error: 26.8099 - val_loss: 645.0889 - val_root_mean_squared_error: 25.3986\n",
            "Epoch 16/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 679.5120 - root_mean_squared_error: 26.0675 - val_loss: 647.6910 - val_root_mean_squared_error: 25.4498\n",
            "\n",
            "--- Training fold 7 of 8 ---\n",
            "Epoch 1/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 697.7612 - root_mean_squared_error: 26.4152 - val_loss: 510.9965 - val_root_mean_squared_error: 22.6052\n",
            "Epoch 2/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 715.2780 - root_mean_squared_error: 26.7447 - val_loss: 530.0941 - val_root_mean_squared_error: 23.0238\n",
            "Epoch 3/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 713.4650 - root_mean_squared_error: 26.7108 - val_loss: 531.7106 - val_root_mean_squared_error: 23.0589\n",
            "Epoch 4/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 724.1862 - root_mean_squared_error: 26.9107 - val_loss: 541.8404 - val_root_mean_squared_error: 23.2775\n",
            "Epoch 5/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 702.6067 - root_mean_squared_error: 26.5067 - val_loss: 548.1909 - val_root_mean_squared_error: 23.4135\n",
            "Epoch 6/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 718.7955 - root_mean_squared_error: 26.8104 - val_loss: 554.8726 - val_root_mean_squared_error: 23.5557\n",
            "Epoch 7/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 703.5916 - root_mean_squared_error: 26.5253 - val_loss: 558.5260 - val_root_mean_squared_error: 23.6332\n",
            "Epoch 8/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 691.9262 - root_mean_squared_error: 26.3045 - val_loss: 571.7765 - val_root_mean_squared_error: 23.9118\n",
            "Epoch 9/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 700.6440 - root_mean_squared_error: 26.4697 - val_loss: 590.7946 - val_root_mean_squared_error: 24.3063\n",
            "Epoch 10/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 698.0233 - root_mean_squared_error: 26.4201 - val_loss: 620.7819 - val_root_mean_squared_error: 24.9155\n",
            "Epoch 11/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 697.9083 - root_mean_squared_error: 26.4180 - val_loss: 612.8865 - val_root_mean_squared_error: 24.7565\n",
            "Epoch 12/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 678.8680 - root_mean_squared_error: 26.0551 - val_loss: 616.6908 - val_root_mean_squared_error: 24.8333\n",
            "Epoch 13/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 699.1226 - root_mean_squared_error: 26.4409 - val_loss: 599.9309 - val_root_mean_squared_error: 24.4935\n",
            "Epoch 14/16\n",
            "425/425 [==============================] - 8s 20ms/step - loss: 698.6239 - root_mean_squared_error: 26.4315 - val_loss: 601.2271 - val_root_mean_squared_error: 24.5199\n",
            "Epoch 15/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 684.0670 - root_mean_squared_error: 26.1547 - val_loss: 603.0691 - val_root_mean_squared_error: 24.5575\n",
            "Epoch 16/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 670.8935 - root_mean_squared_error: 25.9016 - val_loss: 598.9234 - val_root_mean_squared_error: 24.4729\n",
            "\n",
            "--- Training fold 8 of 8 ---\n",
            "Epoch 1/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 694.8179 - root_mean_squared_error: 26.3594 - val_loss: 555.4569 - val_root_mean_squared_error: 23.5681\n",
            "Epoch 2/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 711.5714 - root_mean_squared_error: 26.6753 - val_loss: 563.3377 - val_root_mean_squared_error: 23.7347\n",
            "Epoch 3/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 678.5071 - root_mean_squared_error: 26.0482 - val_loss: 592.5733 - val_root_mean_squared_error: 24.3428\n",
            "Epoch 4/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 706.9662 - root_mean_squared_error: 26.5888 - val_loss: 569.7325 - val_root_mean_squared_error: 23.8691\n",
            "Epoch 5/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 683.8543 - root_mean_squared_error: 26.1506 - val_loss: 574.0192 - val_root_mean_squared_error: 23.9587\n",
            "Epoch 6/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 692.7429 - root_mean_squared_error: 26.3200 - val_loss: 606.5574 - val_root_mean_squared_error: 24.6284\n",
            "Epoch 7/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 694.2424 - root_mean_squared_error: 26.3485 - val_loss: 600.7095 - val_root_mean_squared_error: 24.5094\n",
            "Epoch 8/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 691.7499 - root_mean_squared_error: 26.3011 - val_loss: 603.2690 - val_root_mean_squared_error: 24.5615\n",
            "Epoch 9/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 691.3597 - root_mean_squared_error: 26.2937 - val_loss: 613.6795 - val_root_mean_squared_error: 24.7726\n",
            "Epoch 10/16\n",
            "425/425 [==============================] - 12s 27ms/step - loss: 678.8871 - root_mean_squared_error: 26.0555 - val_loss: 638.2551 - val_root_mean_squared_error: 25.2637\n",
            "Epoch 11/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 673.2688 - root_mean_squared_error: 25.9474 - val_loss: 634.2626 - val_root_mean_squared_error: 25.1846\n",
            "Epoch 12/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 686.3374 - root_mean_squared_error: 26.1980 - val_loss: 639.8010 - val_root_mean_squared_error: 25.2943\n",
            "Epoch 13/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 673.2911 - root_mean_squared_error: 25.9479 - val_loss: 661.6847 - val_root_mean_squared_error: 25.7232\n",
            "Epoch 14/16\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 697.4738 - root_mean_squared_error: 26.4097 - val_loss: 643.7387 - val_root_mean_squared_error: 25.3720\n",
            "Epoch 15/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 677.1295 - root_mean_squared_error: 26.0217 - val_loss: 653.7078 - val_root_mean_squared_error: 25.5677\n",
            "Epoch 16/16\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 677.1608 - root_mean_squared_error: 26.0223 - val_loss: 681.7987 - val_root_mean_squared_error: 26.1113\n",
            "\n",
            "--- Training fold 1 of 8 ---\n",
            "Epoch 1/8\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 681.0898 - root_mean_squared_error: 26.0977 - val_loss: 539.0334 - val_root_mean_squared_error: 23.2171\n",
            "Epoch 2/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 679.3544 - root_mean_squared_error: 26.0644 - val_loss: 568.7549 - val_root_mean_squared_error: 23.8486\n",
            "Epoch 3/8\n",
            "425/425 [==============================] - 8s 20ms/step - loss: 674.9307 - root_mean_squared_error: 25.9794 - val_loss: 575.9368 - val_root_mean_squared_error: 23.9987\n",
            "Epoch 4/8\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 670.4961 - root_mean_squared_error: 25.8939 - val_loss: 605.2632 - val_root_mean_squared_error: 24.6021\n",
            "Epoch 5/8\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 665.1406 - root_mean_squared_error: 25.7903 - val_loss: 596.2695 - val_root_mean_squared_error: 24.4186\n",
            "Epoch 6/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 663.1592 - root_mean_squared_error: 25.7519 - val_loss: 587.2361 - val_root_mean_squared_error: 24.2330\n",
            "Epoch 7/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 661.5008 - root_mean_squared_error: 25.7197 - val_loss: 607.0478 - val_root_mean_squared_error: 24.6383\n",
            "Epoch 8/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 657.5316 - root_mean_squared_error: 25.6424 - val_loss: 615.3798 - val_root_mean_squared_error: 24.8068\n",
            "\n",
            "--- Training fold 2 of 8 ---\n",
            "Epoch 1/8\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 683.8091 - root_mean_squared_error: 26.1497 - val_loss: 551.4029 - val_root_mean_squared_error: 23.4820\n",
            "Epoch 2/8\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 674.2396 - root_mean_squared_error: 25.9661 - val_loss: 573.6533 - val_root_mean_squared_error: 23.9511\n",
            "Epoch 3/8\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 666.7847 - root_mean_squared_error: 25.8222 - val_loss: 568.3640 - val_root_mean_squared_error: 23.8404\n",
            "Epoch 4/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 669.4886 - root_mean_squared_error: 25.8745 - val_loss: 574.4597 - val_root_mean_squared_error: 23.9679\n",
            "Epoch 5/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 682.9648 - root_mean_squared_error: 26.1336 - val_loss: 594.8713 - val_root_mean_squared_error: 24.3900\n",
            "Epoch 6/8\n",
            "425/425 [==============================] - 8s 20ms/step - loss: 683.6475 - root_mean_squared_error: 26.1467 - val_loss: 603.6391 - val_root_mean_squared_error: 24.5691\n",
            "Epoch 7/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 679.7786 - root_mean_squared_error: 26.0726 - val_loss: 594.0767 - val_root_mean_squared_error: 24.3737\n",
            "Epoch 8/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 680.1665 - root_mean_squared_error: 26.0800 - val_loss: 625.5841 - val_root_mean_squared_error: 25.0117\n",
            "\n",
            "--- Training fold 3 of 8 ---\n",
            "Epoch 1/8\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 676.8557 - root_mean_squared_error: 26.0165 - val_loss: 514.8479 - val_root_mean_squared_error: 22.6903\n",
            "Epoch 2/8\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 690.4612 - root_mean_squared_error: 26.2766 - val_loss: 542.5978 - val_root_mean_squared_error: 23.2937\n",
            "Epoch 3/8\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 703.1312 - root_mean_squared_error: 26.5166 - val_loss: 549.4753 - val_root_mean_squared_error: 23.4409\n",
            "Epoch 4/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 683.3987 - root_mean_squared_error: 26.1419 - val_loss: 552.0251 - val_root_mean_squared_error: 23.4952\n",
            "Epoch 5/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 661.5374 - root_mean_squared_error: 25.7204 - val_loss: 554.3892 - val_root_mean_squared_error: 23.5455\n",
            "Epoch 6/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 681.8184 - root_mean_squared_error: 26.1117 - val_loss: 563.8096 - val_root_mean_squared_error: 23.7447\n",
            "Epoch 7/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 653.9395 - root_mean_squared_error: 25.5722 - val_loss: 555.5145 - val_root_mean_squared_error: 23.5694\n",
            "Epoch 8/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 660.9941 - root_mean_squared_error: 25.7098 - val_loss: 576.3090 - val_root_mean_squared_error: 24.0064\n",
            "\n",
            "--- Training fold 4 of 8 ---\n",
            "Epoch 1/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 690.4327 - root_mean_squared_error: 26.2761 - val_loss: 513.5037 - val_root_mean_squared_error: 22.6606\n",
            "Epoch 2/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 695.2499 - root_mean_squared_error: 26.3676 - val_loss: 521.0208 - val_root_mean_squared_error: 22.8259\n",
            "Epoch 3/8\n",
            "425/425 [==============================] - 8s 20ms/step - loss: 675.5816 - root_mean_squared_error: 25.9920 - val_loss: 514.8947 - val_root_mean_squared_error: 22.6913\n",
            "Epoch 4/8\n",
            "425/425 [==============================] - 8s 20ms/step - loss: 680.9785 - root_mean_squared_error: 26.0956 - val_loss: 515.9894 - val_root_mean_squared_error: 22.7154\n",
            "Epoch 5/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 674.8458 - root_mean_squared_error: 25.9778 - val_loss: 531.7906 - val_root_mean_squared_error: 23.0606\n",
            "Epoch 6/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 682.9793 - root_mean_squared_error: 26.1339 - val_loss: 536.3503 - val_root_mean_squared_error: 23.1592\n",
            "Epoch 7/8\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 657.9065 - root_mean_squared_error: 25.6497 - val_loss: 546.9821 - val_root_mean_squared_error: 23.3876\n",
            "Epoch 8/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 676.7471 - root_mean_squared_error: 26.0144 - val_loss: 565.8132 - val_root_mean_squared_error: 23.7868\n",
            "\n",
            "--- Training fold 5 of 8 ---\n",
            "Epoch 1/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 669.0434 - root_mean_squared_error: 25.8659 - val_loss: 519.9123 - val_root_mean_squared_error: 22.8016\n",
            "Epoch 2/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 668.2726 - root_mean_squared_error: 25.8510 - val_loss: 545.5989 - val_root_mean_squared_error: 23.3581\n",
            "Epoch 3/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 660.1526 - root_mean_squared_error: 25.6934 - val_loss: 568.2715 - val_root_mean_squared_error: 23.8384\n",
            "Epoch 4/8\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 669.3075 - root_mean_squared_error: 25.8710 - val_loss: 584.0081 - val_root_mean_squared_error: 24.1663\n",
            "Epoch 5/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 654.9888 - root_mean_squared_error: 25.5927 - val_loss: 577.9137 - val_root_mean_squared_error: 24.0398\n",
            "Epoch 6/8\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 654.6917 - root_mean_squared_error: 25.5869 - val_loss: 571.9352 - val_root_mean_squared_error: 23.9152\n",
            "Epoch 7/8\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 656.7463 - root_mean_squared_error: 25.6271 - val_loss: 591.5584 - val_root_mean_squared_error: 24.3220\n",
            "Epoch 8/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 667.9846 - root_mean_squared_error: 25.8454 - val_loss: 575.2725 - val_root_mean_squared_error: 23.9848\n",
            "\n",
            "--- Training fold 6 of 8 ---\n",
            "Epoch 1/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 664.4367 - root_mean_squared_error: 25.7767 - val_loss: 432.7998 - val_root_mean_squared_error: 20.8038\n",
            "Epoch 2/8\n",
            "425/425 [==============================] - 8s 20ms/step - loss: 693.3454 - root_mean_squared_error: 26.3315 - val_loss: 457.2895 - val_root_mean_squared_error: 21.3843\n",
            "Epoch 3/8\n",
            "425/425 [==============================] - 8s 20ms/step - loss: 689.3815 - root_mean_squared_error: 26.2561 - val_loss: 464.7513 - val_root_mean_squared_error: 21.5581\n",
            "Epoch 4/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 663.9926 - root_mean_squared_error: 25.7681 - val_loss: 471.2083 - val_root_mean_squared_error: 21.7073\n",
            "Epoch 5/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 682.2493 - root_mean_squared_error: 26.1199 - val_loss: 477.0152 - val_root_mean_squared_error: 21.8407\n",
            "Epoch 6/8\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 670.9946 - root_mean_squared_error: 25.9036 - val_loss: 479.1417 - val_root_mean_squared_error: 21.8893\n",
            "Epoch 7/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 679.5402 - root_mean_squared_error: 26.0680 - val_loss: 485.1920 - val_root_mean_squared_error: 22.0271\n",
            "Epoch 8/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 669.8456 - root_mean_squared_error: 25.8814 - val_loss: 477.4970 - val_root_mean_squared_error: 21.8517\n",
            "\n",
            "--- Training fold 7 of 8 ---\n",
            "Epoch 1/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 664.4985 - root_mean_squared_error: 25.7779 - val_loss: 497.8254 - val_root_mean_squared_error: 22.3120\n",
            "Epoch 2/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 671.2052 - root_mean_squared_error: 25.9076 - val_loss: 517.3782 - val_root_mean_squared_error: 22.7460\n",
            "Epoch 3/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 685.1398 - root_mean_squared_error: 26.1752 - val_loss: 531.5084 - val_root_mean_squared_error: 23.0545\n",
            "Epoch 4/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 660.4210 - root_mean_squared_error: 25.6987 - val_loss: 546.8203 - val_root_mean_squared_error: 23.3842\n",
            "Epoch 5/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 680.4262 - root_mean_squared_error: 26.0850 - val_loss: 588.3458 - val_root_mean_squared_error: 24.2558\n",
            "Epoch 6/8\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 670.9888 - root_mean_squared_error: 25.9035 - val_loss: 577.6717 - val_root_mean_squared_error: 24.0348\n",
            "Epoch 7/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 656.8221 - root_mean_squared_error: 25.6285 - val_loss: 572.8184 - val_root_mean_squared_error: 23.9336\n",
            "Epoch 8/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 653.7216 - root_mean_squared_error: 25.5680 - val_loss: 564.5544 - val_root_mean_squared_error: 23.7604\n",
            "\n",
            "--- Training fold 8 of 8 ---\n",
            "Epoch 1/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 666.0083 - root_mean_squared_error: 25.8071 - val_loss: 551.9235 - val_root_mean_squared_error: 23.4931\n",
            "Epoch 2/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 652.4523 - root_mean_squared_error: 25.5431 - val_loss: 574.2346 - val_root_mean_squared_error: 23.9632\n",
            "Epoch 3/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 659.6458 - root_mean_squared_error: 25.6836 - val_loss: 599.4241 - val_root_mean_squared_error: 24.4831\n",
            "Epoch 4/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 661.8663 - root_mean_squared_error: 25.7268 - val_loss: 589.5262 - val_root_mean_squared_error: 24.2802\n",
            "Epoch 5/8\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 640.2580 - root_mean_squared_error: 25.3033 - val_loss: 603.9973 - val_root_mean_squared_error: 24.5764\n",
            "Epoch 6/8\n",
            "425/425 [==============================] - 9s 20ms/step - loss: 658.3454 - root_mean_squared_error: 25.6582 - val_loss: 605.4057 - val_root_mean_squared_error: 24.6050\n",
            "Epoch 7/8\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 659.5344 - root_mean_squared_error: 25.6814 - val_loss: 611.0292 - val_root_mean_squared_error: 24.7190\n",
            "Epoch 8/8\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 651.6014 - root_mean_squared_error: 25.5265 - val_loss: 622.4932 - val_root_mean_squared_error: 24.9498\n",
            "\n",
            "--- Training fold 1 of 8 ---\n",
            "Epoch 1/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 657.5994 - root_mean_squared_error: 25.6437 - val_loss: 548.3572 - val_root_mean_squared_error: 23.4170\n",
            "Epoch 2/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 656.7418 - root_mean_squared_error: 25.6270 - val_loss: 568.6097 - val_root_mean_squared_error: 23.8455\n",
            "Epoch 3/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 642.1357 - root_mean_squared_error: 25.3404 - val_loss: 574.3215 - val_root_mean_squared_error: 23.9650\n",
            "Epoch 4/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 646.5820 - root_mean_squared_error: 25.4280 - val_loss: 582.7215 - val_root_mean_squared_error: 24.1396\n",
            "\n",
            "--- Training fold 2 of 8 ---\n",
            "Epoch 1/4\n",
            "425/425 [==============================] - 11s 25ms/step - loss: 674.2481 - root_mean_squared_error: 25.9663 - val_loss: 509.3115 - val_root_mean_squared_error: 22.5679\n",
            "Epoch 2/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 660.3243 - root_mean_squared_error: 25.6968 - val_loss: 507.4998 - val_root_mean_squared_error: 22.5278\n",
            "Epoch 3/4\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 670.4237 - root_mean_squared_error: 25.8925 - val_loss: 523.6367 - val_root_mean_squared_error: 22.8831\n",
            "Epoch 4/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 650.0140 - root_mean_squared_error: 25.4954 - val_loss: 529.7966 - val_root_mean_squared_error: 23.0173\n",
            "\n",
            "--- Training fold 3 of 8 ---\n",
            "Epoch 1/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 654.4659 - root_mean_squared_error: 25.5825 - val_loss: 502.1649 - val_root_mean_squared_error: 22.4090\n",
            "Epoch 2/4\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 645.9182 - root_mean_squared_error: 25.4149 - val_loss: 521.9427 - val_root_mean_squared_error: 22.8461\n",
            "Epoch 3/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 643.2812 - root_mean_squared_error: 25.3630 - val_loss: 520.0942 - val_root_mean_squared_error: 22.8056\n",
            "Epoch 4/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 636.7303 - root_mean_squared_error: 25.2335 - val_loss: 520.9766 - val_root_mean_squared_error: 22.8249\n",
            "\n",
            "--- Training fold 4 of 8 ---\n",
            "Epoch 1/4\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 674.3884 - root_mean_squared_error: 25.9690 - val_loss: 453.2892 - val_root_mean_squared_error: 21.2906\n",
            "Epoch 2/4\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 664.9516 - root_mean_squared_error: 25.7867 - val_loss: 465.1427 - val_root_mean_squared_error: 21.5672\n",
            "Epoch 3/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 653.3043 - root_mean_squared_error: 25.5598 - val_loss: 477.1812 - val_root_mean_squared_error: 21.8445\n",
            "Epoch 4/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 653.2020 - root_mean_squared_error: 25.5578 - val_loss: 474.4501 - val_root_mean_squared_error: 21.7819\n",
            "\n",
            "--- Training fold 5 of 8 ---\n",
            "Epoch 1/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 669.5966 - root_mean_squared_error: 25.8766 - val_loss: 451.4360 - val_root_mean_squared_error: 21.2470\n",
            "Epoch 2/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 666.4641 - root_mean_squared_error: 25.8160 - val_loss: 441.7781 - val_root_mean_squared_error: 21.0185\n",
            "Epoch 3/4\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 664.4746 - root_mean_squared_error: 25.7774 - val_loss: 468.4706 - val_root_mean_squared_error: 21.6442\n",
            "Epoch 4/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 657.3745 - root_mean_squared_error: 25.6393 - val_loss: 449.1359 - val_root_mean_squared_error: 21.1928\n",
            "\n",
            "--- Training fold 6 of 8 ---\n",
            "Epoch 1/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 657.8779 - root_mean_squared_error: 25.6491 - val_loss: 527.5646 - val_root_mean_squared_error: 22.9688\n",
            "Epoch 2/4\n",
            "425/425 [==============================] - 8s 18ms/step - loss: 668.4503 - root_mean_squared_error: 25.8544 - val_loss: 553.8239 - val_root_mean_squared_error: 23.5335\n",
            "Epoch 3/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 649.9097 - root_mean_squared_error: 25.4933 - val_loss: 547.8995 - val_root_mean_squared_error: 23.4073\n",
            "Epoch 4/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 637.9285 - root_mean_squared_error: 25.2572 - val_loss: 560.2313 - val_root_mean_squared_error: 23.6692\n",
            "\n",
            "--- Training fold 7 of 8 ---\n",
            "Epoch 1/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 672.6142 - root_mean_squared_error: 25.9348 - val_loss: 493.1175 - val_root_mean_squared_error: 22.2062\n",
            "Epoch 2/4\n",
            "425/425 [==============================] - 8s 20ms/step - loss: 648.8639 - root_mean_squared_error: 25.4728 - val_loss: 496.1354 - val_root_mean_squared_error: 22.2741\n",
            "Epoch 3/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 665.3901 - root_mean_squared_error: 25.7952 - val_loss: 506.9533 - val_root_mean_squared_error: 22.5156\n",
            "Epoch 4/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 666.7828 - root_mean_squared_error: 25.8221 - val_loss: 516.5473 - val_root_mean_squared_error: 22.7277\n",
            "\n",
            "--- Training fold 8 of 8 ---\n",
            "Epoch 1/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 640.4758 - root_mean_squared_error: 25.3076 - val_loss: 509.3876 - val_root_mean_squared_error: 22.5696\n",
            "Epoch 2/4\n",
            "425/425 [==============================] - 8s 20ms/step - loss: 650.2565 - root_mean_squared_error: 25.5001 - val_loss: 523.0575 - val_root_mean_squared_error: 22.8705\n",
            "Epoch 3/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 644.8663 - root_mean_squared_error: 25.3942 - val_loss: 525.0863 - val_root_mean_squared_error: 22.9148\n",
            "Epoch 4/4\n",
            "425/425 [==============================] - 8s 19ms/step - loss: 654.5698 - root_mean_squared_error: 25.5846 - val_loss: 532.9590 - val_root_mean_squared_error: 23.0859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NWIf7nJPlcB",
        "colab_type": "text"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0mjrPUQkkAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TrainingLoss = [d['loss'] for d in results]\n",
        "TrainingRMSE = [d['root_mean_squared_error'] for d in results]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcCCsO9jgTZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ValidationLoss = [d['val_loss'] for d in results]\n",
        "ValidationRMSE = [d['val_root_mean_squared_error'] for d in results]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ACNqYm2koTN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "71ca6cd9-77db-4acb-a998-54f2c781f05e"
      },
      "source": [
        "print(\"Training Loss:\" + str(TrainingLoss))\n",
        "print(\"Validation Loss:\" + str(ValidationLoss))\n",
        "print(\"Training RMSE:\" + str(TrainingRMSE))\n",
        "print(\"Validation RMSE:\" + str(ValidationRMSE))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss:[[2377.216796875, 1536.7845458984375, 1337.8807373046875, 1213.454833984375, 1104.9326171875, 1061.8232421875, 1032.123291015625, 1007.9619750976562, 1003.9927978515625, 981.7777099609375, 967.8533325195312, 970.4300537109375, 951.310546875, 926.2779541015625, 920.0761108398438, 899.1424560546875], [903.9021606445312, 881.1030883789062, 880.2463989257812, 861.8655395507812, 843.8834838867188, 844.92529296875, 834.102294921875, 832.4763793945312, 823.0702514648438, 812.8389282226562, 811.3445434570312, 816.8641357421875, 803.40576171875, 787.6437377929688, 790.470458984375, 792.5463256835938], [834.5139770507812, 838.05322265625, 818.5826416015625, 802.8523559570312, 809.042236328125, 793.4544677734375, 791.22119140625, 800.9178466796875, 779.703125, 798.4453735351562, 774.63671875, 774.4484252929688, 766.0023803710938, 768.211669921875, 769.773193359375, 788.6385498046875], [774.3411254882812, 756.2119140625, 760.5687866210938, 741.7708129882812, 756.9509887695312, 748.016357421875, 747.0140991210938, 752.8359985351562, 728.4073486328125, 742.4678955078125, 728.561279296875, 731.0925903320312, 707.4110717773438, 744.83203125, 730.9606323242188, 724.5790405273438], [752.8564453125, 742.3358764648438, 721.993896484375, 723.007568359375, 724.4437866210938, 735.6922607421875, 728.3965454101562, 737.6998901367188, 732.2678833007812, 701.3118286132812, 720.9191284179688, 718.1954956054688, 709.490966796875, 696.9306640625, 698.4012451171875, 709.157470703125], [721.5867919921875, 726.5634155273438, 720.2332763671875, 721.7825927734375, 717.9135131835938, 717.1007080078125, 708.53759765625, 701.1109619140625, 705.7885131835938, 700.5888671875, 709.4085693359375, 707.2400512695312, 685.36279296875, 673.5077514648438, 718.7684936523438, 679.5120239257812], [697.7611694335938, 715.2780151367188, 713.4649658203125, 724.1862182617188, 702.606689453125, 718.7954711914062, 703.591552734375, 691.9262084960938, 700.64404296875, 698.0233154296875, 697.9082641601562, 678.8679809570312, 699.1226196289062, 698.6239013671875, 684.0670166015625, 670.8934936523438], [694.81787109375, 711.5713500976562, 678.5071411132812, 706.9661865234375, 683.8543090820312, 692.7428588867188, 694.242431640625, 691.7499389648438, 691.3597412109375, 678.8870849609375, 673.268798828125, 686.33740234375, 673.2910766601562, 697.4737548828125, 677.1294555664062, 677.1607666015625], [681.0897827148438, 679.3543701171875, 674.9307250976562, 670.49609375, 665.1405639648438, 663.1592407226562, 661.5007934570312, 657.5316162109375], [683.80908203125, 674.2396240234375, 666.78466796875, 669.4885864257812, 682.96484375, 683.6475219726562, 679.778564453125, 680.16650390625], [676.855712890625, 690.4612426757812, 703.1311645507812, 683.3987426757812, 661.5374145507812, 681.8184204101562, 653.939453125, 660.994140625], [690.4327392578125, 695.2498779296875, 675.5816040039062, 680.9784545898438, 674.8457641601562, 682.9793090820312, 657.906494140625, 676.7470703125], [669.0433959960938, 668.2725830078125, 660.152587890625, 669.3074951171875, 654.98876953125, 654.6917114257812, 656.746337890625, 667.984619140625], [664.4367065429688, 693.3453979492188, 689.3814697265625, 663.9925537109375, 682.249267578125, 670.9945678710938, 679.5402221679688, 669.8456420898438], [664.4984741210938, 671.2052001953125, 685.1398315429688, 660.4210205078125, 680.4262084960938, 670.9888305664062, 656.8221435546875, 653.7216186523438], [666.00830078125, 652.4523315429688, 659.645751953125, 661.8662719726562, 640.2579956054688, 658.3453979492188, 659.5343627929688, 651.6013793945312], [657.5994262695312, 656.7417602539062, 642.1356811523438, 646.58203125], [674.2481079101562, 660.3242797851562, 670.4237060546875, 650.0140380859375], [654.4659423828125, 645.918212890625, 643.2811889648438, 636.7302856445312], [674.3883666992188, 664.9515991210938, 653.3043212890625, 653.2019653320312], [669.5966186523438, 666.4640502929688, 664.474609375, 657.37451171875], [657.8779296875, 668.4502563476562, 649.90966796875, 637.928466796875], [672.6141967773438, 648.8638916015625, 665.3900756835938, 666.7828369140625], [640.4757690429688, 650.2565307617188, 644.8662719726562, 654.5697631835938]]\n",
            "Validation Loss:[[1767.4676513671875, 1360.30908203125, 1204.309814453125, 1100.273681640625, 1027.0460205078125, 979.7888793945312, 981.4491577148438, 958.8474731445312, 944.4002075195312, 933.7854614257812, 944.5191650390625, 931.4454956054688, 894.5056762695312, 908.8477172851562, 899.97509765625, 898.139404296875], [866.4249877929688, 863.1742553710938, 881.4622192382812, 880.7939453125, 907.9522705078125, 922.3811645507812, 952.023681640625, 929.0912475585938, 924.8030395507812, 921.9091186523438, 906.7442626953125, 952.3907470703125, 936.908447265625, 948.2281494140625, 944.8389282226562, 961.8174438476562], [648.0596923828125, 677.9410400390625, 680.5433349609375, 690.6993408203125, 709.25390625, 703.867919921875, 703.986572265625, 730.1265258789062, 721.2822265625, 731.8480834960938, 732.3421020507812, 758.763427734375, 737.9454345703125, 731.5734252929688, 741.8222045898438, 767.0629272460938], [651.2572021484375, 653.7747192382812, 680.439453125, 697.0355224609375, 707.1043090820312, 711.2343139648438, 726.63720703125, 745.1140747070312, 746.2294311523438, 782.5177612304688, 775.0989990234375, 758.9641723632812, 775.7366333007812, 785.2406616210938, 781.61865234375, 799.1590576171875], [566.590087890625, 592.83740234375, 594.0120849609375, 611.2371826171875, 609.24609375, 633.0952758789062, 631.017822265625, 634.7578125, 650.7064208984375, 662.8159790039062, 681.8330078125, 668.5792236328125, 685.6685180664062, 673.6849365234375, 694.2158813476562, 689.514892578125], [566.3299560546875, 577.5032348632812, 576.2108154296875, 582.658203125, 615.7227172851562, 605.2255859375, 621.4053344726562, 621.3880004882812, 641.3483276367188, 638.58837890625, 647.6380004882812, 656.4861450195312, 644.0869140625, 638.333251953125, 645.0889282226562, 647.6910400390625], [510.99652099609375, 530.0941162109375, 531.7106323242188, 541.8403930664062, 548.1908569335938, 554.87255859375, 558.5260009765625, 571.7764892578125, 590.7945556640625, 620.7818603515625, 612.8865356445312, 616.6907958984375, 599.930908203125, 601.22705078125, 603.069091796875, 598.9234008789062], [555.4569091796875, 563.3377075195312, 592.5733032226562, 569.7325439453125, 574.0191650390625, 606.557373046875, 600.7095336914062, 603.2689819335938, 613.6795043945312, 638.2550659179688, 634.2626342773438, 639.801025390625, 661.6846923828125, 643.7387084960938, 653.7078247070312, 681.7987060546875], [539.033447265625, 568.7549438476562, 575.936767578125, 605.26318359375, 596.26953125, 587.2361450195312, 607.0477905273438, 615.3797607421875], [551.4028930664062, 573.6533203125, 568.364013671875, 574.459716796875, 594.871337890625, 603.6390991210938, 594.07666015625, 625.5841064453125], [514.847900390625, 542.5977783203125, 549.475341796875, 552.0250854492188, 554.3892211914062, 563.8096313476562, 555.5145263671875, 576.3090209960938], [513.5037231445312, 521.020751953125, 514.8947143554688, 515.9893798828125, 531.7905883789062, 536.3502807617188, 546.9820556640625, 565.8131713867188], [519.9122924804688, 545.5989379882812, 568.2715454101562, 584.0081176757812, 577.9136962890625, 571.9351806640625, 591.5584106445312, 575.2724609375], [432.7998046875, 457.2895202636719, 464.7513122558594, 471.208251953125, 477.0151672363281, 479.1416931152344, 485.19195556640625, 477.4969787597656], [497.82537841796875, 517.3782348632812, 531.5084228515625, 546.8202514648438, 588.3457641601562, 577.6716918945312, 572.818359375, 564.5543823242188], [551.9234619140625, 574.234619140625, 599.4241333007812, 589.5262451171875, 603.997314453125, 605.4057006835938, 611.0292358398438, 622.4931640625], [548.357177734375, 568.6096801757812, 574.321533203125, 582.7214965820312], [509.3115234375, 507.49981689453125, 523.63671875, 529.796630859375], [502.16485595703125, 521.9426879882812, 520.0941772460938, 520.9766235351562], [453.2891845703125, 465.1427307128906, 477.1812438964844, 474.4501037597656], [451.43597412109375, 441.7781066894531, 468.47064208984375, 449.13592529296875], [527.5645751953125, 553.8238525390625, 547.8994750976562, 560.2313232421875], [493.1175231933594, 496.1353759765625, 506.9532775878906, 516.5473022460938], [509.38763427734375, 523.0574951171875, 525.0863037109375, 532.958984375]]\n",
            "Training RMSE:[[48.756710052490234, 39.20184326171875, 36.57705307006836, 34.834678649902344, 33.24052810668945, 32.585628509521484, 32.12667465209961, 31.748416900634766, 31.68584632873535, 31.333332061767578, 31.110342025756836, 31.15172576904297, 30.84332275390625, 30.434814453125, 30.33275604248047, 29.98570442199707], [30.064966201782227, 29.683380126953125, 29.668947219848633, 29.357545852661133, 29.049673080444336, 29.067598342895508, 28.880828857421875, 28.8526668548584, 28.68920135498047, 28.510330200195312, 28.48410987854004, 28.580835342407227, 28.34441375732422, 28.064990997314453, 28.115306854248047, 28.152198791503906], [28.887954711914062, 28.949148178100586, 28.610883712768555, 28.33465003967285, 28.443668365478516, 28.168323516845703, 28.12865447998047, 28.300491333007812, 27.92316436767578, 28.25677490234375, 27.83229637145996, 27.82891273498535, 27.676748275756836, 27.716630935668945, 27.744787216186523, 28.08270835876465], [27.82698631286621, 27.49930763244629, 27.578411102294922, 27.235469818115234, 27.51274299621582, 27.34988784790039, 27.331558227539062, 27.437856674194336, 26.989023208618164, 27.24826431274414, 26.99187469482422, 27.03872299194336, 26.597200393676758, 27.291610717773438, 27.036283493041992, 26.918004989624023], [27.438230514526367, 27.24584197998047, 26.869943618774414, 26.8887996673584, 26.91549301147461, 27.123647689819336, 26.98882293701172, 27.16063117980957, 27.060449600219727, 26.48229217529297, 26.849937438964844, 26.799169540405273, 26.636272430419922, 26.399444580078125, 26.427282333374023, 26.6300106048584], [26.862367630004883, 26.9548397064209, 26.837162017822266, 26.866012573242188, 26.793909072875977, 26.778736114501953, 26.618370056152344, 26.478500366210938, 26.566680908203125, 26.468639373779297, 26.63472557067871, 26.593984603881836, 26.179433822631836, 25.952028274536133, 26.809858322143555, 26.06745147705078], [26.41516876220703, 26.74468231201172, 26.710765838623047, 26.910707473754883, 26.506729125976562, 26.810361862182617, 26.525300979614258, 26.30449104309082, 26.469680786132812, 26.42013168334961, 26.417953491210938, 26.055095672607422, 26.440927505493164, 26.431493759155273, 26.154674530029297, 25.901611328125], [26.359397888183594, 26.675294876098633, 26.04817008972168, 26.588836669921875, 26.15060806274414, 26.320009231567383, 26.348480224609375, 26.30113983154297, 26.293720245361328, 26.055461883544922, 25.947423934936523, 26.198041915893555, 25.947853088378906, 26.40972900390625, 26.021711349487305, 26.02231216430664], [26.09769630432129, 26.06442642211914, 25.979429244995117, 25.893939971923828, 25.790319442749023, 25.75187873840332, 25.71965789794922, 25.642379760742188], [26.149744033813477, 25.96612548828125, 25.822174072265625, 25.87447738647461, 26.133596420288086, 26.14665412902832, 26.07256317138672, 26.080001831054688], [26.016450881958008, 26.276628494262695, 26.516620635986328, 26.141897201538086, 25.720369338989258, 26.111652374267578, 25.572240829467773, 25.709806442260742], [26.276086807250977, 26.367591857910156, 25.991952896118164, 26.095563888549805, 25.977792739868164, 26.133872985839844, 25.649688720703125, 26.014362335205078], [25.865873336791992, 25.850969314575195, 25.693435668945312, 25.8709774017334, 25.592748641967773, 25.586944580078125, 25.62706184387207, 25.84539794921875], [25.776670455932617, 26.331453323364258, 26.256074905395508, 25.76805305480957, 26.119901657104492, 25.903562545776367, 26.0679931640625, 25.881376266479492], [25.777868270874023, 25.907629013061523, 26.1751766204834, 25.698657989501953, 26.084980010986328, 25.903451919555664, 25.628541946411133, 25.56797981262207], [25.80713653564453, 25.54314613342285, 25.683568954467773, 25.726760864257812, 25.303319931030273, 25.65824317932129, 25.681400299072266, 25.5264835357666], [25.643701553344727, 25.62697410583496, 25.340396881103516, 25.427976608276367], [25.96628761291504, 25.696775436401367, 25.892541885375977, 25.495372772216797], [25.58253288269043, 25.414920806884766, 25.36298942565918, 25.2335147857666], [25.9689884185791, 25.78665542602539, 25.559818267822266, 25.557815551757812], [25.87656593322754, 25.81596565246582, 25.77740478515625, 25.63931655883789], [25.649131774902344, 25.85440444946289, 25.49332618713379, 25.257246017456055], [25.93480682373047, 25.472806930541992, 25.795156478881836, 25.8221378326416], [25.3076229095459, 25.5001277923584, 25.394216537475586, 25.58456039428711]]\n",
            "Validation RMSE:[[42.041259765625, 36.88236999511719, 34.70316696166992, 33.170372009277344, 32.04755783081055, 31.30158042907715, 31.328088760375977, 30.965261459350586, 30.731094360351562, 30.557903289794922, 30.733030319213867, 30.51959228515625, 29.908287048339844, 30.1471004486084, 29.999584197998047, 29.96897315979004], [29.43509864807129, 29.37982749938965, 29.689430236816406, 29.678173065185547, 30.132246017456055, 30.370729446411133, 30.854881286621094, 30.480998992919922, 30.410573959350586, 30.362957000732422, 30.112194061279297, 30.860828399658203, 30.60896110534668, 30.79331398010254, 30.738231658935547, 31.013181686401367], [25.457015991210938, 26.03730010986328, 26.08722496032715, 26.281160354614258, 26.631820678710938, 26.53050994873047, 26.532745361328125, 27.02085304260254, 26.85669708251953, 27.052690505981445, 27.061819076538086, 27.5456600189209, 27.165151596069336, 27.0476131439209, 27.236413955688477, 27.695899963378906], [25.51974105834961, 25.569019317626953, 26.085233688354492, 26.401430130004883, 26.591432571411133, 26.668975830078125, 26.956209182739258, 27.296777725219727, 27.31719970703125, 27.97351837158203, 27.840599060058594, 27.549304962158203, 27.852048873901367, 28.022146224975586, 27.957443237304688, 28.26940155029297], [23.803152084350586, 24.34825325012207, 24.372364044189453, 24.72321128845215, 24.682910919189453, 25.16138458251953, 25.120067596435547, 25.194400787353516, 25.508947372436523, 25.74521255493164, 26.1119327545166, 25.85689926147461, 26.185272216796875, 25.955440521240234, 26.347976684570312, 26.258615493774414], [23.797687530517578, 24.03129768371582, 24.004390716552734, 24.13831329345703, 24.81376075744629, 24.601333618164062, 24.928003311157227, 24.927656173706055, 25.32485580444336, 25.270305633544922, 25.448732376098633, 25.621986389160156, 25.378868103027344, 25.265256881713867, 25.398601531982422, 25.44977569580078], [22.60523223876953, 23.023773193359375, 23.05885124206543, 23.2774658203125, 23.413475036621094, 23.55573272705078, 23.633153915405273, 23.911848068237305, 24.306264877319336, 24.915494918823242, 24.756546020507812, 24.83325958251953, 24.493486404418945, 24.51993179321289, 24.557464599609375, 24.472911834716797], [23.568132400512695, 23.7347354888916, 24.34282875061035, 23.869070053100586, 23.958696365356445, 24.628385543823242, 24.509376525878906, 24.561534881591797, 24.77255630493164, 25.263710021972656, 25.184572219848633, 25.294288635253906, 25.72323226928711, 25.372005462646484, 25.567710876464844, 26.11127471923828], [23.21709442138672, 23.848583221435547, 23.998682022094727, 24.602096557617188, 24.418630599975586, 24.232955932617188, 24.63833999633789, 24.806848526000977], [23.481969833374023, 23.951061248779297, 23.84038543701172, 23.9678897857666, 24.389984130859375, 24.569067001342773, 24.373687744140625, 25.01167869567871], [22.69025993347168, 23.29372787475586, 23.44089126586914, 23.495214462280273, 23.54547119140625, 23.74467658996582, 23.569355010986328, 24.006437301635742], [22.660619735717773, 22.825878143310547, 22.69129180908203, 22.71539878845215, 23.060585021972656, 23.159236907958984, 23.38764762878418, 23.786827087402344], [22.801586151123047, 23.35805892944336, 23.83844757080078, 24.166259765625, 24.03983497619629, 23.9151668548584, 24.32197380065918, 23.984838485717773], [20.80384063720703, 21.384328842163086, 21.55809211730957, 21.707332611083984, 21.84067726135254, 21.889305114746094, 22.02707290649414, 21.851703643798828], [22.312000274658203, 22.74595069885254, 23.054466247558594, 23.384187698364258, 24.255840301513672, 24.034801483154297, 23.933624267578125, 23.760353088378906], [23.493051528930664, 23.963193893432617, 24.483139038085938, 24.280160903930664, 24.576356887817383, 24.60499382019043, 24.719005584716797, 24.949813842773438], [23.417028427124023, 23.845537185668945, 23.96500587463379, 24.139625549316406], [22.56793212890625, 22.527755737304688, 22.88311004638672, 23.017311096191406], [22.409034729003906, 22.846065521240234, 22.805572509765625, 22.824913024902344], [21.29058837890625, 21.567167282104492, 21.844478607177734, 21.781875610351562], [21.24702262878418, 21.018518447875977, 21.644182205200195, 21.192827224731445], [22.968774795532227, 23.533462524414062, 23.40725326538086, 23.669206619262695], [22.206249237060547, 22.274097442626953, 22.515623092651367, 22.727676391601562], [22.569618225097656, 22.870450973510742, 22.914762496948242, 23.085905075073242]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4bq0G0SrKks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "7990321b-b65b-4e6c-e9ef-504cde58c236"
      },
      "source": [
        "def flattenMeans(lst):\n",
        "    retList = []\n",
        "    for item in lst:\n",
        "        retList.append(mean(item))\n",
        "    return retList\n",
        "\n",
        "TrainingLoss_means = flattenMeans(TrainingLoss)\n",
        "TrainingRMSE_means = flattenMeans(TrainingRMSE)\n",
        "ValidationLoss_means = flattenMeans(ValidationLoss)\n",
        "ValidationRMSE_means = flattenMeans(ValidationRMSE)\n",
        "\n",
        "print(\"Training Loss Means:\" + str(TrainingLoss_means))\n",
        "print(\"Validation Loss Means:\" + str(ValidationLoss_means))\n",
        "print(\"Training RMSE Means:\" + str(TrainingRMSE_means))\n",
        "print(\"Validation RMSE Means:\" + str(ValidationRMSE_means))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Loss Means:[1143.3149375915527, 832.5430488586426, 794.2810859680176, 742.2513732910156, 722.0688095092773, 707.1878700256348, 699.7350578308105, 688.0850105285645, 669.1503982543945, 677.6099243164062, 676.5170364379883, 679.3401641845703, 662.6484375, 676.7232284545898, 667.9029159545898, 656.2139739990234, 650.7647247314453, 663.7525329589844, 645.0989074707031, 661.4615631103516, 664.4774475097656, 653.5415802001953, 663.4127502441406, 647.5420837402344]\n",
            "Validation Loss Means:[1045.9443740844727, 918.8089942932129, 716.6948852539062, 736.0726356506348, 642.4882888793945, 620.3565521240234, 574.5194854736328, 614.5364799499512, 586.8651962280273, 585.7563934326172, 551.1210632324219, 530.793083190918, 566.8088302612305, 468.1118354797363, 549.6153106689453, 594.7542343139648, 568.5024719238281, 517.5611724853516, 516.2945861816406, 467.5158157348633, 452.70516204833984, 547.3798065185547, 503.18836975097656, 522.6226043701172]\n",
            "Training RMSE Means:[33.49683606624603, 28.84793710708618, 28.180362343788147, 27.242700338363647, 26.86976683139801, 26.591418743133545, 26.45123600959778, 26.230511903762817, 25.86746597290039, 26.030667066574097, 26.00820827484131, 26.063364028930664, 25.741676092147827, 26.0131356716156, 25.84303569793701, 25.616257429122925, 25.509762287139893, 25.762744426727295, 25.398489475250244, 25.718319416046143, 25.777313232421875, 25.56352710723877, 25.756227016448975, 25.446631908416748]\n",
            "Validation RMSE Means:[32.18782639503479, 30.30760169029236, 26.76503598690033, 27.116905093193054, 25.336002588272095, 24.900051593780518, 23.958430767059326, 24.778881907463074, 24.220403909683228, 24.19821548461914, 23.473254203796387, 23.035935640335083, 23.80327081680298, 21.63279414176941, 23.435153007507324, 24.38371443748474, 23.84179925918579, 22.749027252197266, 22.721396446228027, 21.62102746963501, 21.27563762664795, 23.39467430114746, 22.430911540985107, 22.86018419265747]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EF4HOQ7jquY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "c31bac8c-22f4-47ba-a550-9a2267bd0041"
      },
      "source": [
        "plt.plot(TrainingLoss_means, 'b')\n",
        "plt.plot(ValidationLoss_means, 'r')\n",
        "plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kddS14lNkGdR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "fc4a3d06-4dd9-4a71-9378-e2abf6f61a55"
      },
      "source": [
        "plt.plot(TrainingRMSE_means, 'b')\n",
        "plt.plot(ValidationRMSE_means, 'r')\n",
        "plt.legend(['Training RMSE', 'Validation RMSE'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXUhyUy7t9mP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "cda07575-835b-499a-b327-3120e5ac457c"
      },
      "source": [
        "print(\"For the last run (last 8 folds):\")\n",
        "\n",
        "print(\"Minimum Training Loss:\\t\" + str(min(TrainingLoss_means[-8:])))\n",
        "print(\"Minimum Validation Loss:\\t\" + str(min(ValidationLoss_means[-8:])))\n",
        "print(\"Mean Training Loss:\\t\" + str(mean(TrainingLoss_means[-8:])))\n",
        "print(\"Mean Validation Loss:\\t\" + str(mean(ValidationLoss_means[-8:])))\n",
        "\n",
        "print(\"Minimum Training RMSE:\\t\" + str(min(TrainingRMSE_means[-8:])))\n",
        "print(\"Minimum Validation RMSE:\\t\" + str(min(ValidationRMSE_means[-8:])))\n",
        "print(\"Mean Training RMSE:\\t\" + str(mean(TrainingRMSE_means[-8:])))\n",
        "print(\"Mean Validation RMSE:\\t\" + str(mean(ValidationRMSE_means[-8:])))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For the last run (last 8 folds):\n",
            "Minimum Training Loss:\t645.0989074707031\n",
            "Minimum Validation Loss:\t452.70516204833984\n",
            "Mean Training Loss:\t656.2564487457275\n",
            "Mean Validation Loss:\t511.971248626709\n",
            "Minimum Training RMSE:\t25.398489475250244\n",
            "Minimum Validation RMSE:\t21.27563762664795\n",
            "Mean Training RMSE:\t25.616626858711243\n",
            "Mean Validation RMSE:\t22.61183226108551\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}